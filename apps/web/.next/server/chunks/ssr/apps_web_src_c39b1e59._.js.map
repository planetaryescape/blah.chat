{"version":3,"sources":["../../../../../../apps/web/src/lib/ai/benchmarks.ts","../../../../../../apps/web/src/lib/ai/models.ts","../../../../../../apps/web/src/hooks/useRecentModels.ts"],"sourcesContent":["import type { ModelConfig } from \"./models\";\nimport type {\n  BenchmarkScores,\n  ComputedMetrics,\n  CostTier,\n  SpeedTier,\n} from \"./types\";\n\n/**\n * Tier 1: Hardcoded benchmark data for flagship models\n * Sources:\n * - SWE-bench Verified (coding)\n * - AIME 2025 (intelligence)\n * - GPQA Diamond (reasoning)\n * All scores normalized to 0-100 scale\n */\nexport const BENCHMARK_DATA: Record<string, BenchmarkScores> = {\n  // OpenAI\n  \"openai:gpt-5\": { intelligence: 94, coding: 85, reasoning: 88 },\n  \"openai:gpt-5-mini\": { intelligence: 75, coding: 68, reasoning: 70 },\n  \"openai:gpt-5-nano\": { intelligence: 65, coding: 60, reasoning: 62 },\n\n  // Anthropic\n  \"anthropic:claude-opus-4.5\": { intelligence: 95, coding: 81, reasoning: 90 },\n  \"anthropic:claude-3.5-sonnet\": {\n    intelligence: 88,\n    coding: 78,\n    reasoning: 85,\n  },\n  \"anthropic:claude-3.5-haiku\": { intelligence: 75, coding: 68, reasoning: 72 },\n\n  // Google\n  \"google:gemini-2.5-pro\": { intelligence: 86, coding: 72, reasoning: 84 },\n  \"google:gemini-2.5-flash\": { intelligence: 85, coding: 70, reasoning: 82 },\n\n  // xAI\n  \"xai:grok-4\": { intelligence: 100, coding: 75, reasoning: 88 },\n  \"xai:grok-4-fast\": { intelligence: 92, coding: 72, reasoning: 85 },\n  \"xai:grok-3\": { intelligence: 88, coding: 70, reasoning: 82 },\n\n  // DeepSeek\n  \"deepseek:deepseek-v3\": { intelligence: 87, coding: 78, reasoning: 85 },\n  \"deepseek:deepseek-r1\": { intelligence: 90, coding: 80, reasoning: 88 },\n\n  // Meta\n  \"meta:llama-3.3-70b\": { intelligence: 78, coding: 72, reasoning: 75 },\n  \"meta:llama-3.1-405b\": { intelligence: 82, coding: 75, reasoning: 78 },\n  \"meta:llama-3.1-70b\": { intelligence: 76, coding: 70, reasoning: 73 },\n};\n\n/**\n * Speed tier mapping based on provider/model characteristics\n * Sources: Groq, Cerebras benchmarks, provider documentation\n */\nconst SPEED_TIERS: Record<string, { tier: SpeedTier; tps?: number }> = {\n  // Ultra-fast inference (>500 TPS)\n  cerebras: { tier: \"ultra-fast\", tps: 2522 },\n  sambanova: { tier: \"ultra-fast\", tps: 794 },\n\n  // Fast inference (200-500 TPS)\n  groq: { tier: \"fast\", tps: 549 },\n\n  // Specific fast models\n  \"gemini-2.5-flash\": { tier: \"fast\" },\n  \"gpt-5-nano\": { tier: \"fast\" },\n\n  // Reasoning models (slower due to thinking)\n  \"gpt-5\": { tier: \"slow\" },\n  \"claude-opus-4.5\": { tier: \"slow\" },\n  \"deepseek-r1\": { tier: \"slow\" },\n  \"gemini-2.0-flash-thinking\": { tier: \"medium\" }, // Fast but with thinking\n};\n\n/**\n * Provider-level intelligence averages for estimation\n */\nconst PROVIDER_AVERAGES: Record<string, number> = {\n  openai: 85,\n  anthropic: 80,\n  google: 75,\n  xai: 85,\n  deepseek: 82,\n  meta: 75,\n  mistral: 72,\n  perplexity: 70,\n  groq: 70, // Inference provider, uses open models\n  cerebras: 70,\n  alibaba: 68,\n  minimax: 68,\n  zhipu: 68,\n  kimi: 70,\n  zai: 68,\n};\n\n/**\n * Model tier multipliers based on name suffix\n */\nconst TIER_MULTIPLIERS: Record<string, number> = {\n  mini: 0.7,\n  nano: 0.6,\n  haiku: 0.75,\n  flash: 0.85,\n  base: 1.0,\n  pro: 1.2,\n  opus: 1.25,\n  ultra: 1.3,\n};\n\n/**\n * Get benchmark scores for a model using 3-tier fallback\n */\nexport function getBenchmarkScores(model: ModelConfig): BenchmarkScores {\n  // Tier 1: Check hardcoded data\n  const hardcoded = BENCHMARK_DATA[model.id];\n  if (hardcoded) {\n    return hardcoded;\n  }\n\n  // Tier 2: Estimate based on provider and model tier\n  const provider = model.provider;\n  const providerAvg = PROVIDER_AVERAGES[provider] || 70;\n\n  // Detect tier from model name\n  let multiplier = 1.0;\n  const lowerName = model.name.toLowerCase();\n  for (const [tier, mult] of Object.entries(TIER_MULTIPLIERS)) {\n    if (lowerName.includes(tier)) {\n      multiplier = mult;\n      break;\n    }\n  }\n\n  let intelligence = Math.round(providerAvg * multiplier);\n  let coding = Math.round(providerAvg * multiplier * 0.9); // Coding slightly lower\n  let reasoning = Math.round(providerAvg * multiplier * 0.95);\n\n  // Tier 3: Adjust based on capabilities\n  if (model.capabilities.includes(\"extended-thinking\")) {\n    reasoning += 15;\n    intelligence += 10;\n  }\n  if (model.capabilities.includes(\"thinking\")) {\n    reasoning += 10;\n    intelligence += 5;\n  }\n  if (model.capabilities.includes(\"vision\")) {\n    // Vision models typically mid-tier\n    intelligence = Math.min(intelligence, 85);\n  }\n  if (model.isLocal) {\n    // Local models typically lower benchmarks\n    intelligence = Math.min(intelligence, 75);\n    coding = Math.min(coding, 70);\n  }\n\n  // Clamp to 0-100 range\n  return {\n    intelligence: Math.max(0, Math.min(100, intelligence)),\n    coding: Math.max(0, Math.min(100, coding)),\n    reasoning: Math.max(0, Math.min(100, reasoning)),\n  };\n}\n\n/**\n * Determine speed tier for a model\n */\nfunction getSpeedTier(model: ModelConfig): { tier: SpeedTier; tps?: number } {\n  // Check provider-level speed\n  const providerSpeed = SPEED_TIERS[model.provider];\n  if (providerSpeed) {\n    return providerSpeed;\n  }\n\n  // Check model-specific speed (by name fragment)\n  const lowerName = model.name.toLowerCase();\n  const lowerID = model.id.toLowerCase();\n\n  for (const [key, speed] of Object.entries(SPEED_TIERS)) {\n    if (lowerName.includes(key) || lowerID.includes(key)) {\n      return speed;\n    }\n  }\n\n  // Default: reasoning models slow, local models medium, others medium\n  if (model.capabilities.includes(\"extended-thinking\")) {\n    return { tier: \"slow\" };\n  }\n  if (model.capabilities.includes(\"thinking\") && !lowerName.includes(\"flash\")) {\n    return { tier: \"slow\" };\n  }\n  if (model.isLocal) {\n    return { tier: \"medium\" };\n  }\n\n  return { tier: \"medium\" }; // Safe default\n}\n\n/**\n * Calculate cost tier based on pricing\n */\nfunction getCostTier(model: ModelConfig): { tier: CostTier; avgCost: number } {\n  if (model.isLocal) {\n    return { tier: \"budget\", avgCost: 0 };\n  }\n\n  const avgCost = (model.pricing.input + model.pricing.output) / 2;\n\n  if (avgCost < 1) {\n    return { tier: \"budget\", avgCost };\n  }\n  if (avgCost < 10) {\n    return { tier: \"balanced\", avgCost };\n  }\n  return { tier: \"premium\", avgCost };\n}\n\n/**\n * Compute percentile for a score among all models\n * @param score The score to rank\n * @param allScores Array of all scores to compare against\n * @returns Percentile (0-100)\n */\nfunction computePercentile(\n  score: number | undefined,\n  allScores: number[],\n): number | undefined {\n  if (score === undefined || allScores.length === 0) {\n    return undefined;\n  }\n\n  const validScores = allScores.filter((s) => s !== undefined && s > 0);\n  if (validScores.length === 0) {\n    return undefined;\n  }\n\n  const sortedScores = [...validScores].sort((a, b) => a - b);\n  const rank = sortedScores.filter((s) => s < score).length;\n  return Math.round((rank / sortedScores.length) * 100);\n}\n\n/**\n * Compute all metrics for a model\n * This is the main function that orchestrates all calculations\n */\nexport function computeModelMetrics(\n  model: ModelConfig,\n  allModels?: ModelConfig[],\n): ComputedMetrics {\n  // Get benchmark scores (real or estimated)\n  const scores = getBenchmarkScores(model);\n  const hasPublicBenchmarks = BENCHMARK_DATA[model.id] !== undefined;\n\n  // Get speed tier\n  const { tier: speedTier, tps: speedTps } = getSpeedTier(model);\n\n  // Get cost tier\n  const { tier: costTier, avgCost: costPerMillion } = getCostTier(model);\n\n  // Compute percentiles if allModels provided\n  let intelligencePercentile: number | undefined;\n  let codingPercentile: number | undefined;\n  let reasoningPercentile: number | undefined;\n\n  if (allModels) {\n    const allIntelligence = allModels.map(\n      (m) => getBenchmarkScores(m).intelligence!,\n    );\n    const allCoding = allModels.map((m) => getBenchmarkScores(m).coding!);\n    const allReasoning = allModels.map((m) => getBenchmarkScores(m).reasoning!);\n\n    intelligencePercentile = computePercentile(\n      scores.intelligence,\n      allIntelligence,\n    );\n    codingPercentile = computePercentile(scores.coding, allCoding);\n    reasoningPercentile = computePercentile(scores.reasoning, allReasoning);\n  }\n\n  return {\n    speedTier,\n    speedTps,\n    costTier,\n    costPerMillion,\n    intelligencePercentile,\n    codingPercentile,\n    reasoningPercentile,\n    hasPublicBenchmarks,\n  };\n}\n\n/**\n * Get comparative text for intelligence\n */\nexport function getIntelligenceText(percentile: number | undefined): string {\n  if (percentile === undefined) {\n    return \"Competitive\";\n  }\n  if (percentile >= 95) return \"Top 5%\";\n  if (percentile >= 90) return \"Top 10%\";\n  if (percentile >= 75) return \"Top 25%\";\n  if (percentile >= 60) return \"Above average\";\n  return \"Competitive\";\n}\n\n/**\n * Get comparative text for speed\n */\nexport function getSpeedText(metrics: ComputedMetrics): string {\n  const { speedTier, speedTps } = metrics;\n\n  if (speedTps) {\n    return `${speedTps.toLocaleString()} TPS`;\n  }\n\n  switch (speedTier) {\n    case \"ultra-fast\":\n      return \"Instant (simple tasks)\";\n    case \"fast\":\n      return \"Quick responses\";\n    case \"medium\":\n      return \"Standard speed\";\n    case \"slow\":\n      return \"Slower (deep thinking)\";\n  }\n}\n\n/**\n * Get comparative text for cost\n */\nexport function getCostText(metrics: ComputedMetrics): string {\n  const { costTier, costPerMillion } = metrics;\n\n  if (costPerMillion === 0) {\n    return \"Free (local)\";\n  }\n\n  const formatted = `$${costPerMillion.toFixed(2)}/M avg`;\n\n  switch (costTier) {\n    case \"budget\":\n      return `${formatted} (Best for volume)`;\n    case \"balanced\":\n      return `${formatted} (Moderate cost)`;\n    case \"premium\":\n      return `${formatted} (Complex tasks only)`;\n  }\n}\n","import { computeModelMetrics } from \"./benchmarks\";\nimport type { GatewayName } from \"./providers\";\nimport type { ReasoningConfig } from \"./reasoning/types\";\nimport type { BenchmarkScores, ComputedMetrics, SpeedTier } from \"./types\";\n\nexport interface ModelConfig {\n  id: string;\n  /** Model creator/vendor (OpenAI, Anthropic, etc.) - used for grouping and icons */\n  provider:\n    | \"openai\"\n    | \"anthropic\"\n    | \"google\"\n    | \"xai\"\n    | \"perplexity\"\n    | \"groq\"\n    | \"cerebras\"\n    | \"minimax\"\n    | \"deepseek\"\n    | \"kimi\"\n    | \"zai\"\n    | \"meta\"\n    | \"mistral\"\n    | \"alibaba\"\n    | \"zhipu\";\n  name: string;\n  description?: string;\n  contextWindow: number;\n  pricing: {\n    input: number;\n    output: number;\n    cached?: number;\n    reasoning?: number;\n  };\n  capabilities: (\n    | \"vision\"\n    | \"function-calling\"\n    | \"thinking\"\n    | \"extended-thinking\"\n    | \"image-generation\"\n  )[];\n  isLocal?: boolean;\n  actualModelId?: string;\n  reasoning?: ReasoningConfig;\n  /** Fallback inference hosts within Vercel AI Gateway (e.g., [\"cerebras\", \"groq\"]) */\n  hostOrder?: string[];\n  /** Mark preview/beta/experimental models */\n  isExperimental?: boolean;\n  /** Knowledge cutoff date for the model (e.g., \"November 2025\", \"Real-time search\") */\n  knowledgeCutoff?: string;\n  /** Gateway/SDK for routing requests. Defaults to \"vercel\" (Vercel AI Gateway) */\n  gateway?: GatewayName;\n  /** User-friendly plain-language description for non-technical users */\n  userFriendlyDescription?: string;\n  /** Technical use case summary for power users */\n  bestFor?: string;\n  /** Benchmark scores (intelligence, coding, reasoning) - optional override */\n  benchmarks?: BenchmarkScores;\n  /** Speed tier - optional override (computed if not provided) */\n  speedTier?: SpeedTier;\n  /** Mark as pro/premium model requiring tier access */\n  isPro?: boolean;\n  /** Hide from model picker - for internal app ops only */\n  isInternalOnly?: boolean;\n}\n\nexport const MODEL_CONFIG: Record<string, ModelConfig> = {\n  // OpenAI\n\n  // GPT-5 Series (Size Variants)\n  \"openai:gpt-5\": {\n    id: \"openai:gpt-5\",\n    provider: \"openai\",\n    name: \"GPT-5\",\n    description:\n      \"Flagship GPT-5 with advanced reasoning and multimodal capabilities\",\n    contextWindow: 200000,\n    pricing: { input: 2.5, output: 10.0, cached: 0.25 },\n    capabilities: [\"thinking\", \"vision\", \"function-calling\"],\n    reasoning: {\n      type: \"openai-reasoning-effort\",\n      effortMapping: { low: \"low\", medium: \"medium\", high: \"high\" },\n      summaryLevel: \"detailed\",\n      useResponsesAPI: true,\n    },\n    knowledgeCutoff: \"April 2025\",\n    userFriendlyDescription:\n      \"Most powerful GPT-5. Handles the most complex tasks with advanced reasoning, vision, and deep thinking.\",\n    bestFor: \"Complex reasoning, research, advanced multimodal tasks\",\n  },\n  \"openai:gpt-5-mini\": {\n    id: \"openai:gpt-5-mini\",\n    provider: \"openai\",\n    name: \"GPT-5 Mini\",\n    description: \"Compact GPT-5 variant balancing cost and performance\",\n    contextWindow: 200000,\n    pricing: { input: 0.15, output: 0.6, cached: 0.015 },\n    capabilities: [\"vision\", \"function-calling\"],\n    knowledgeCutoff: \"April 2025\",\n    userFriendlyDescription:\n      \"Fast and affordable. Great balance of performance and cost for everyday tasks.\",\n    bestFor: \"General purpose, high-volume applications, cost-conscious use\",\n  },\n  \"openai:gpt-5-nano\": {\n    id: \"openai:gpt-5-nano\",\n    provider: \"openai\",\n    name: \"GPT-5 Nano\",\n    description: \"Smallest, fastest GPT-5 variant for simple queries\",\n    contextWindow: 200000,\n    pricing: { input: 0.04, output: 0.16, cached: 0.004 },\n    capabilities: [\"function-calling\"],\n    knowledgeCutoff: \"April 2025\",\n    userFriendlyDescription:\n      \"Lightning-fast and ultra-cheap. Perfect for simple questions and high-volume applications.\",\n    bestFor: \"Simple queries, maximum speed, ultra-low cost\",\n  },\n\n  // GPT-5.1 Family (November 2025)\n  \"openai:gpt-5.1\": {\n    id: \"openai:gpt-5.1\",\n    provider: \"openai\",\n    name: \"GPT-5.1\",\n    description:\n      \"Latest flagship with adaptive reasoning and 24h prompt caching\",\n    contextWindow: 256000,\n    pricing: { input: 1.25, output: 10.0, cached: 0.125 },\n    capabilities: [\"thinking\", \"vision\", \"function-calling\"],\n    reasoning: {\n      type: \"openai-reasoning-effort\",\n      effortMapping: { low: \"low\", medium: \"medium\", high: \"high\" },\n      summaryLevel: \"detailed\",\n      useResponsesAPI: true,\n    },\n    knowledgeCutoff: \"November 2025\",\n    userFriendlyDescription:\n      \"Best all-around model. Can read a novel's worth of text, analyze images, and think deeply about complex problems.\",\n    bestFor: \"General purpose, adaptive reasoning, multimodal tasks\",\n  },\n  \"openai:gpt-5.1-codex\": {\n    id: \"openai:gpt-5.1-codex\",\n    provider: \"openai\",\n    name: \"GPT-5.1 Codex\",\n    description: \"GPT-5.1 optimized for agentic coding tasks\",\n    contextWindow: 256000,\n    pricing: { input: 1.25, output: 10.0, cached: 0.125 },\n    capabilities: [\"thinking\", \"function-calling\"],\n    reasoning: {\n      type: \"openai-reasoning-effort\",\n      effortMapping: { low: \"low\", medium: \"medium\", high: \"high\" },\n      summaryLevel: \"detailed\",\n      useResponsesAPI: true,\n    },\n    knowledgeCutoff: \"November 2025\",\n    userFriendlyDescription:\n      \"Expert coding assistant. Writes code, debugs issues, and understands entire projects.\",\n    bestFor: \"Agentic coding, software engineering, complex refactoring\",\n  },\n  \"openai:gpt-5.1-instant\": {\n    id: \"openai:gpt-5.1-instant\",\n    provider: \"openai\",\n    name: \"GPT-5.1 Instant\",\n    description:\n      \"Fast conversational variant with improved tone and personalization\",\n    contextWindow: 128000,\n    pricing: { input: 0.25, output: 2.0, cached: 0.025 },\n    capabilities: [\"vision\", \"function-calling\"],\n    knowledgeCutoff: \"November 2025\",\n    userFriendlyDescription:\n      \"Fast and personable. Great for natural conversations with a friendly, adaptive tone.\",\n    bestFor: \"Conversational tasks, quick responses, personalized interactions\",\n  },\n\n  // GPT-5.2 Family (December 2025)\n  \"openai:gpt-5.2\": {\n    id: \"openai:gpt-5.2\",\n    provider: \"openai\",\n    name: \"GPT-5.2\",\n    description:\n      \"OpenAI's best general-purpose model. Most intelligent model for general and agentic tasks.\",\n    contextWindow: 400000,\n    pricing: { input: 1.75, output: 14.0, cached: 0.17 },\n    capabilities: [\"thinking\", \"vision\", \"function-calling\"],\n    reasoning: {\n      type: \"openai-reasoning-effort\",\n      effortMapping: { low: \"low\", medium: \"medium\", high: \"high\" },\n      summaryLevel: \"detailed\",\n      useResponsesAPI: true,\n    },\n    knowledgeCutoff: \"April 2025\",\n    userFriendlyDescription:\n      \"Most intelligent model yet. Advances GPT-5 with 400k context, deep reasoning, and massive knowledge.\",\n    bestFor: \"Deep reasoning, massive context tasks, complex agentic workflows\",\n  },\n  \"openai:gpt-5.2-chat\": {\n    id: \"openai:gpt-5.2-chat\",\n    provider: \"openai\",\n    name: \"GPT-5.2 Chat\",\n    description: \"The model powering ChatGPT. Best general-purpose model.\",\n    contextWindow: 128000,\n    pricing: { input: 1.75, output: 14.0, cached: 0.17 },\n    capabilities: [\"vision\", \"function-calling\"],\n    knowledgeCutoff: \"April 2025\",\n    userFriendlyDescription:\n      \"The brain behind ChatGPT. Intelligent, versatile, and optimized for natural conversation.\",\n    bestFor: \"General conversation, content creation, everyday intelligence\",\n  },\n  \"openai:gpt-oss-20b\": {\n    id: \"openai:gpt-oss-20b\",\n    provider: \"openai\",\n    name: \"GPT-OSS 20B\",\n    description:\n      \"Compact MoE optimized for low-latency and edge deployments (1000 T/sec)\",\n    contextWindow: 131000,\n    pricing: { input: 0.1, output: 0.5 },\n    capabilities: [\"function-calling\", \"thinking\"],\n    hostOrder: [\"cerebras\", \"groq\"],\n    userFriendlyDescription:\n      \"Instant responses. Blazing-fast model for when you need answers right now.\",\n    bestFor: \"Ultra-low latency, real-time applications, edge deployment\",\n    isInternalOnly: true,\n  },\n  \"openai:gpt-oss-120b\": {\n    id: \"openai:gpt-oss-120b\",\n    provider: \"openai\",\n    name: \"GPT-OSS 120B\",\n    description:\n      \"Extremely capable general-purpose LLM with strong, controllable reasoning\",\n    contextWindow: 131000,\n    pricing: { input: 0.15, output: 0.6 },\n    capabilities: [\"function-calling\", \"thinking\"],\n    hostOrder: [\"cerebras\", \"groq\", \"fireworks\"],\n    userFriendlyDescription:\n      \"Powerful and versatile. Handles complex tasks with strong reasoning at very fast speeds.\",\n    bestFor: \"General purpose, fast reasoning, high-performance tasks\",\n    isInternalOnly: true,\n  },\n\n  // Anthropic\n  \"anthropic:claude-opus-4.5\": {\n    id: \"anthropic:claude-opus-4.5\",\n    provider: \"anthropic\",\n    name: \"Claude 4.5 Opus\",\n    description: \"Most capable Claude for complex tasks\",\n    contextWindow: 200000,\n    pricing: { input: 5.0, output: 25.0, cached: 0.5 },\n    capabilities: [\n      \"vision\",\n      \"function-calling\",\n      \"thinking\",\n      \"extended-thinking\",\n    ],\n    reasoning: {\n      type: \"anthropic-extended-thinking\",\n      budgetMapping: { low: 5000, medium: 15000, high: 30000 },\n      betaHeader: \"interleaved-thinking-2025-05-14\",\n    },\n    knowledgeCutoff: \"April 2025\",\n    userFriendlyDescription:\n      \"Most capable Claude. Writes sophisticated code, handles complex analysis, and excels at nuanced tasks.\",\n    bestFor: \"Complex coding, autonomous agents, software engineering\",\n  },\n  \"anthropic:claude-sonnet-4.5\": {\n    id: \"anthropic:claude-sonnet-4.5\",\n    provider: \"anthropic\",\n    name: \"Claude 4.5 Sonnet\",\n    description: \"Balanced performance and speed\",\n    contextWindow: 200000,\n    pricing: { input: 3.0, output: 15.0, cached: 0.3 },\n    capabilities: [\n      \"vision\",\n      \"function-calling\",\n      \"thinking\",\n      \"extended-thinking\",\n    ],\n    reasoning: {\n      type: \"anthropic-extended-thinking\",\n      budgetMapping: { low: 5000, medium: 15000, high: 30000 },\n      betaHeader: \"interleaved-thinking-2025-05-14\",\n    },\n    knowledgeCutoff: \"April 2025\",\n    userFriendlyDescription:\n      \"Balanced performer. Good at coding, analysis, and can even control computers. Works for most tasks.\",\n    bestFor: \"Coding, computer use, balanced performance\",\n  },\n  \"anthropic:claude-haiku-4.5\": {\n    id: \"anthropic:claude-haiku-4.5\",\n    provider: \"anthropic\",\n    name: \"Claude 4.5 Haiku\",\n    description: \"Fast and cost-effective\",\n    contextWindow: 200000,\n    pricing: { input: 1.0, output: 5.0, cached: 0.1 },\n    capabilities: [\"vision\", \"function-calling\"],\n    knowledgeCutoff: \"April 2025\",\n    userFriendlyDescription:\n      \"Quick and efficient. Fast responses for high-volume work without breaking the bank.\",\n    bestFor:\n      \"Quick responses, high-volume processing, cost-sensitive applications\",\n  },\n\n  // Google\n  \"google:gemini-2.5-flash\": {\n    id: \"google:gemini-2.5-flash\",\n    provider: \"google\",\n    name: \"Gemini 2.5 Flash\",\n    description:\n      \"Production model with thinking - fast, multimodal, 1M context\",\n    contextWindow: 1048576,\n    pricing: {\n      input: 0.15,\n      output: 0.6,\n      cached: 0.019,\n      reasoning: 3.5, // Thinking output pricing (6x higher!)\n    },\n    capabilities: [\"vision\", \"function-calling\", \"thinking\"],\n    reasoning: {\n      type: \"google-thinking-budget\",\n      budgetMapping: {\n        low: 4096,\n        medium: 12288,\n        high: 24576,\n      },\n    },\n    userFriendlyDescription:\n      \"Speed demon. Handles massive documents (can read a thousand-page book!) and responds instantly. Great for real-time tasks.\",\n    bestFor:\n      \"Speed-critical tasks, long-context processing, real-time applications\",\n    knowledgeCutoff: \"January 2025\",\n  },\n  \"google:gemini-2.5-pro\": {\n    id: \"google:gemini-2.5-pro\",\n    provider: \"google\",\n    name: \"Gemini 2.5 Pro\",\n    description:\n      \"Most capable with extended thinking - 2M context, best quality\",\n    contextWindow: 2097152,\n    pricing: {\n      input: 1.25,\n      output: 5.0,\n      cached: 0.31,\n    },\n    capabilities: [\"vision\", \"function-calling\", \"thinking\"],\n    reasoning: {\n      type: \"google-thinking-budget\",\n      budgetMapping: {\n        low: 8192,\n        medium: 16384,\n        high: 24576,\n      },\n    },\n    knowledgeCutoff: \"January 2025\",\n    userFriendlyDescription:\n      \"Deep thinker with huge memory. Can analyze entire books (2 million words!) and think through complex problems.\",\n    bestFor: \"Deep reasoning, complex multi-step analysis, research\",\n  },\n  \"google:gemini-3-flash\": {\n    id: \"google:gemini-3-flash\",\n    provider: \"google\",\n    name: \"Gemini 3 Flash\",\n    description:\n      \"Google's most intelligent model built for speed. Frontier intelligence with superior search and grounding.\",\n    contextWindow: 1000000,\n    pricing: {\n      input: 0.5,\n      output: 3.0,\n      cached: 0.125,\n    },\n    capabilities: [\"vision\", \"function-calling\", \"thinking\"],\n    reasoning: {\n      type: \"google-thinking-budget\",\n      budgetMapping: {\n        low: 4096,\n        medium: 12288,\n        high: 24576,\n      },\n    },\n    knowledgeCutoff: \"August 2025\",\n    userFriendlyDescription:\n      \"Fast frontier intelligence. Google's smartest model optimized for speed with 1M context and built-in search grounding.\",\n    bestFor:\n      \"Speed-critical tasks, real-time applications, search-grounded responses\",\n  },\n  \"google:gemini-2.0-flash\": {\n    id: \"google:gemini-2.0-flash\",\n    provider: \"google\",\n    name: \"Gemini 2.0 Flash\",\n    description: \"Stable multimodal - fast, cost-effective, no thinking\",\n    contextWindow: 1048576,\n    pricing: {\n      input: 0.075,\n      output: 0.3,\n      cached: 0.019,\n    },\n    capabilities: [\"vision\", \"function-calling\"],\n    knowledgeCutoff: \"August 2024\",\n    userFriendlyDescription:\n      \"Fast and multimodal. Quick processing of text, images, and more at an affordable price.\",\n    bestFor: \"Quick multimodal processing, budget-conscious, general purpose\",\n  },\n  \"google:gemini-2.0-flash-lite\": {\n    id: \"google:gemini-2.0-flash-lite\",\n    provider: \"google\",\n    name: \"Gemini 2.0 Flash Lite\",\n    description: \"Ultra-cost-optimized - fastest, cheapest, no thinking\",\n    contextWindow: 1048576,\n    pricing: {\n      input: 0.0375,\n      output: 0.15,\n      cached: 0.0095,\n    },\n    capabilities: [\"vision\", \"function-calling\"],\n    knowledgeCutoff: \"August 2024\",\n    userFriendlyDescription:\n      \"Ultra-budget friendly. Extremely fast and cheap for high-volume simple tasks.\",\n    bestFor: \"Maximum cost efficiency, high-volume processing, simple queries\",\n  },\n  \"google:gemini-3-pro-preview\": {\n    id: \"google:gemini-3-pro-preview\",\n    name: \"Gemini 3 Pro (Preview)\",\n    provider: \"google\",\n    contextWindow: 1048576, // 1M tokens\n    pricing: {\n      input: 2.0, // $2/MTok (≤200K context)\n      output: 12.0, // $12/MTok (≤200K context)\n      // Note: >200K is $4/$24 but flat pricing doesn't support tiering\n    },\n    capabilities: [\"function-calling\", \"thinking\"],\n    description:\n      \"Third-generation flagship model with advanced reasoning (experimental)\",\n    isExperimental: true,\n    reasoning: {\n      type: \"google-thinking-level\",\n      levelMapping: {\n        low: \"low\",\n        medium: \"medium\",\n        high: \"high\",\n      },\n      includeThoughts: true,\n    },\n    knowledgeCutoff: \"August 2025\",\n    userFriendlyDescription:\n      \"Next-generation preview. Google's latest and most advanced model with cutting-edge reasoning.\",\n    bestFor: \"Advanced reasoning, research, testing future capabilities\",\n  },\n\n  \"google:gemini-3-pro-image-preview\": {\n    id: \"google:gemini-3-pro-image-preview\",\n    name: \"Gemini 3 Pro Image (Nano Banana Pro)\",\n    provider: \"google\",\n    contextWindow: 65536, // 65K tokens\n    pricing: {\n      input: 2.0, // Same as Gemini 3 Pro (text tokens)\n      output: 12.0, // Text output (image output is $120/M but varies)\n    },\n    capabilities: [\"image-generation\", \"vision\", \"thinking\"],\n    description:\n      \"Image generation model with advanced visual understanding and reasoning (marketing name: Nano Banana Pro)\",\n    isExperimental: true,\n    reasoning: {\n      type: \"google-thinking-level\",\n      levelMapping: {\n        low: \"low\",\n        medium: \"medium\",\n        high: \"high\",\n      },\n      includeThoughts: true,\n    },\n    knowledgeCutoff: \"August 2025\",\n    userFriendlyDescription:\n      \"Creates images. Generate visuals from text descriptions with advanced understanding. Free preview.\",\n    bestFor: \"Image generation, visual creativity, design prototyping\",\n  },\n\n  \"google:gemini-2.5-flash-image\": {\n    id: \"google:gemini-2.5-flash-image\",\n    provider: \"google\",\n    name: \"Gemini 2.5 Flash Image\",\n    description: \"Cost-effective image generation with hybrid reasoning\",\n    contextWindow: 32768,\n    pricing: {\n      input: 0.3,\n      output: 2.5,\n    },\n    capabilities: [\"image-generation\", \"vision\"],\n    isExperimental: true,\n    knowledgeCutoff: \"August 2025\",\n    userFriendlyDescription:\n      \"Fast image generation. Cost-effective visual creation with locale-aware, culturally appropriate outputs.\",\n    bestFor: \"Fast, cost-effective slide image generation\",\n  },\n\n  // xAI - Note: Vercel AI Gateway uses \"xai/model-name\" format\n  \"xai:grok-4-fast\": {\n    id: \"xai:grok-4-fast\",\n    provider: \"xai\",\n    name: \"Grok 4 Fast\",\n    description: \"Faster Grok 4 variant (non-reasoning)\",\n    contextWindow: 256000,\n    pricing: { input: 2.0, output: 8.0 },\n    capabilities: [\"function-calling\"],\n    actualModelId: \"grok-4-fast-non-reasoning\",\n    knowledgeCutoff: \"July 2025\",\n    userFriendlyDescription:\n      \"Fast and conversational. Quick responses with Grok's signature personality and humor.\",\n    bestFor: \"Conversational tasks, quick responses, general purpose\",\n  },\n\n  \"xai:grok-4.1-fast\": {\n    id: \"xai:grok-4.1-fast\",\n    provider: \"xai\",\n    name: \"Grok 4.1 Fast\",\n    description: \"Best agentic tool-calling model (non-reasoning)\",\n    contextWindow: 2000000,\n    pricing: { input: 1.0, output: 4.0 },\n    capabilities: [\"function-calling\"],\n    actualModelId: \"grok-4.1-fast-non-reasoning\",\n    knowledgeCutoff: \"July 2025\",\n    userFriendlyDescription:\n      \"Massive memory. Can handle 2 million words of context - perfect for huge documents and long conversations.\",\n    bestFor: \"Long-context tasks, agentic workflows, tool use\",\n  },\n  \"xai:grok-4.1-fast-reasoning\": {\n    id: \"xai:grok-4.1-fast-reasoning\",\n    provider: \"xai\",\n    name: \"Grok 4.1 Fast (Reasoning)\",\n    description: \"Best agentic tool-calling model with reasoning\",\n    contextWindow: 2000000,\n    pricing: { input: 1.0, output: 4.0 },\n    capabilities: [\"thinking\", \"function-calling\"],\n    actualModelId: \"grok-4.1-fast-reasoning\",\n    knowledgeCutoff: \"July 2025\",\n    userFriendlyDescription:\n      \"Fast reasoning at scale. Combines thinking capabilities with speed, affordability, and huge context.\",\n    bestFor:\n      \"Cost-efficient reasoning, high-volume thinking tasks, agentic workflows\",\n  },\n  \"xai:grok-code-fast-1\": {\n    id: \"xai:grok-code-fast-1\",\n    provider: \"xai\",\n    name: \"Grok Code Fast\",\n    description: \"Speedy reasoning for coding\",\n    contextWindow: 128000,\n    pricing: { input: 0.5, output: 2.0 },\n    capabilities: [\"thinking\"],\n    knowledgeCutoff: \"July 2025\",\n    userFriendlyDescription:\n      \"Fast coding assistant. Quick code generation, debugging, and problem-solving at affordable prices.\",\n    bestFor: \"Coding, debugging, cost-efficient development\",\n  },\n\n  // Perplexity (Only 4 models available in Vercel AI Gateway)\n  \"perplexity:sonar-reasoning-pro\": {\n    id: \"perplexity:sonar-reasoning-pro\",\n    provider: \"perplexity\",\n    name: \"Sonar Reasoning Pro\",\n    description: \"DeepSeek R1 powered reasoning with CoT\",\n    contextWindow: 127000,\n    pricing: { input: 2.0, output: 8.0 },\n    capabilities: [\"thinking\"],\n    knowledgeCutoff: \"Real-time search\",\n    userFriendlyDescription:\n      \"Connected to the web with deep thinking. Searches current information and reasons about real-world facts with careful analysis.\",\n    bestFor:\n      \"Research, web-grounded reasoning, factual accuracy, real-time information\",\n  },\n  \"perplexity:sonar-pro\": {\n    id: \"perplexity:sonar-pro\",\n    provider: \"perplexity\",\n    name: \"Sonar Pro\",\n    description: \"Advanced search with grounding\",\n    contextWindow: 200000,\n    pricing: { input: 3.0, output: 15.0 },\n    capabilities: [],\n    knowledgeCutoff: \"Real-time search\",\n    userFriendlyDescription:\n      \"Advanced web search. Finds and analyzes current information with citation grounding for accuracy.\",\n    bestFor: \"Research, web search, current events, fact-checking\",\n  },\n\n  \"perplexity:sonar-reasoning\": {\n    id: \"perplexity:sonar-reasoning\",\n    provider: \"perplexity\",\n    name: \"Sonar Reasoning\",\n    description: \"Fast real-time reasoning\",\n    contextWindow: 127000,\n    pricing: { input: 1.0, output: 5.0 },\n    capabilities: [\"thinking\"],\n    knowledgeCutoff: \"Real-time search\",\n    userFriendlyDescription:\n      \"Fast web-connected thinking. Quick searches combined with reasoning for up-to-date insights.\",\n    bestFor: \"Quick research, real-time reasoning, affordable web search\",\n  },\n  \"perplexity:sonar\": {\n    id: \"perplexity:sonar\",\n    provider: \"perplexity\",\n    name: \"Sonar\",\n    description: \"Lightweight, fast search\",\n    contextWindow: 127000,\n    pricing: { input: 1.0, output: 1.0 },\n    capabilities: [],\n    knowledgeCutoff: \"Real-time search\",\n    userFriendlyDescription:\n      \"Quick web search. Lightweight and fast for when you just need current information.\",\n    bestFor: \"Fast search, current events, budget-conscious research\",\n  },\n  // Meta Models (via Vercel AI Gateway)\n  \"meta:llama-3.3-70b\": {\n    id: \"meta:llama-3.3-70b\",\n    provider: \"meta\",\n    name: \"Llama 3.3 70B\",\n    description: \"Enhanced reasoning, tool use, multilingual. 128K context.\",\n    contextWindow: 128000,\n    pricing: { input: 0.59, output: 0.79 },\n    capabilities: [\"function-calling\"],\n    hostOrder: [\"cerebras\", \"groq\"],\n    userFriendlyDescription:\n      \"Powerful open-source model. Great for coding, speaks many languages, and you control where it runs.\",\n    bestFor: \"Open-source, coding, multilingual tasks, local deployment\",\n    isInternalOnly: true,\n  },\n  \"meta:llama-4-maverick\": {\n    id: \"meta:llama-4-maverick\",\n    provider: \"meta\",\n    name: \"Llama 4 Maverick 17B\",\n    description:\n      \"Llama 4's largest MoE model with coding, reasoning, and image capabilities.\",\n    contextWindow: 128000,\n    pricing: { input: 0.2, output: 0.6 },\n    capabilities: [\"vision\", \"function-calling\"],\n    hostOrder: [\"cerebras\", \"groq\"],\n    userFriendlyDescription:\n      \"Next-gen Llama. Largest open model with coding, reasoning, and image understanding.\",\n    bestFor: \"Advanced coding, multimodal tasks, open-source\",\n  },\n  \"meta:llama-4-scout\": {\n    id: \"meta:llama-4-scout\",\n    provider: \"meta\",\n    name: \"Llama 4 Scout 17B\",\n    description: \"Smaller Llama 4 MoE. Fast and efficient for general tasks.\",\n    contextWindow: 128000,\n    pricing: { input: 0.1, output: 0.3 },\n    capabilities: [\"function-calling\"],\n    hostOrder: [\"cerebras\", \"groq\"],\n    userFriendlyDescription:\n      \"Fast and efficient. Compact Llama 4 model great for everyday tasks at low cost.\",\n    bestFor: \"General purpose, cost efficiency, fast processing\",\n  },\n\n  // Mistral Models (via Vercel AI Gateway)\n  \"mistral:mistral-large-3\": {\n    id: \"mistral:mistral-large-3\",\n    provider: \"mistral\",\n    name: \"Mistral Large 3\",\n    description:\n      \"Most capable Mistral model. Sparse MoE with 41B active / 675B total params.\",\n    contextWindow: 256000,\n    pricing: { input: 0.5, output: 1.5 },\n    capabilities: [\"function-calling\", \"vision\"],\n    userFriendlyDescription:\n      \"European alternative. Handles general tasks well with vision support at competitive pricing.\",\n    bestFor: \"General purpose, cost-effective, European data residency\",\n  },\n  \"mistral:devstral-small\": {\n    id: \"mistral:devstral-small\",\n    provider: \"mistral\",\n    name: \"Mistral Devstral Small\",\n    description: \"Agentic LLM optimized for software engineering tasks.\",\n    contextWindow: 128000,\n    pricing: { input: 0.1, output: 0.3 },\n    capabilities: [\"function-calling\"],\n    userFriendlyDescription:\n      \"Coding specialist. Optimized for software engineering with agentic capabilities.\",\n    bestFor: \"Software development, agentic coding, European alternative\",\n  },\n\n  // Alibaba Qwen Models (via Vercel AI Gateway)\n  \"alibaba:qwen3-max\": {\n    id: \"alibaba:qwen3-max\",\n    provider: \"alibaba\",\n    name: \"Qwen 3 Max\",\n    description:\n      \"SOTA agent and tool invocation. Specialized for complex agentic scenarios.\",\n    contextWindow: 262000,\n    pricing: { input: 1.2, output: 6.0, cached: 0.24 },\n    capabilities: [\"function-calling\", \"thinking\"],\n    userFriendlyDescription:\n      \"Expert agent. Excels at using tools and handling complex multi-step workflows.\",\n    bestFor: \"Agentic tasks, tool invocation, complex workflows\",\n  },\n  \"alibaba:qwen3-coder-480b\": {\n    id: \"alibaba:qwen3-coder-480b\",\n    provider: \"alibaba\",\n    name: \"Qwen 3 Coder 480B\",\n    description: \"480B MoE coding specialist optimized for agentic tasks.\",\n    contextWindow: 131072,\n    pricing: { input: 0.35, output: 1.4 },\n    capabilities: [\"function-calling\"],\n    userFriendlyDescription:\n      \"Massive coding model. 480 billion parameters specialized for sophisticated code generation.\",\n    bestFor: \"Advanced coding, large-scale projects, agentic development\",\n    isInternalOnly: true,\n  },\n\n  // Moonshot AI Kimi Models (via Vercel AI Gateway)\n  \"moonshotai:kimi-k2\": {\n    id: \"moonshotai:kimi-k2\",\n    provider: \"kimi\",\n    name: \"Kimi K2\",\n    description:\n      \"1T MoE (32B active). Optimized for agentic tool use, reasoning, and code synthesis.\",\n    contextWindow: 131000,\n    pricing: { input: 0.6, output: 2.5 },\n    capabilities: [\"function-calling\"],\n    hostOrder: [\"deepinfra\", \"fireworks\"],\n    userFriendlyDescription:\n      \"Agentic powerhouse. Excels at using tools and generating code with sophisticated reasoning.\",\n    bestFor: \"Agentic workflows, tool use, code synthesis\",\n    isInternalOnly: true,\n  },\n  \"moonshotai:kimi-k2-thinking\": {\n    id: \"moonshotai:kimi-k2-thinking\",\n    provider: \"kimi\",\n    name: \"Kimi K2 Thinking\",\n    description:\n      \"Advanced thinking agent. 200-300 sequential tool calls. SOTA on HLE, BrowseComp.\",\n    contextWindow: 262000,\n    pricing: { input: 0.6, output: 2.5, cached: 0.15 },\n    capabilities: [\"function-calling\", \"thinking\"],\n    hostOrder: [\"fireworks\", \"deepinfra\"],\n    userFriendlyDescription:\n      \"Advanced thinking agent. Can make hundreds of tool calls in sequence for complex multi-step tasks.\",\n    bestFor: \"Complex agentic tasks, multi-step reasoning, advanced workflows\",\n    isInternalOnly: true,\n  },\n\n  // MiniMax Models (via Vercel AI Gateway)\n  \"minimax:minimax-m2\": {\n    id: \"minimax:minimax-m2\",\n    provider: \"minimax\",\n    name: \"MiniMax M2\",\n    description:\n      \"Compact MoE (230B total / 10B active). Elite coding and agentic performance.\",\n    contextWindow: 205000,\n    pricing: { input: 0.3, output: 1.2, cached: 0.03 },\n    capabilities: [\"function-calling\"],\n    hostOrder: [\"deepinfra\"],\n    userFriendlyDescription:\n      \"Efficient powerhouse. Compact model with elite coding and agentic performance.\",\n    bestFor: \"Coding, agentic tasks, efficient performance\",\n  },\n  \"minimax:minimax-m2.1\": {\n    id: \"minimax:minimax-m2.1\",\n    provider: \"minimax\",\n    name: \"MiniMax M2.1\",\n    description:\n      \"Optimized for coding, tool use, instruction following, and long-horizon planning.\",\n    contextWindow: 205000,\n    pricing: { input: 0.3, output: 1.2, cached: 0.03 },\n    capabilities: [\"function-calling\"],\n    userFriendlyDescription:\n      \"Robust coding model. Excels at tool use and long-horizon planning.\",\n    bestFor: \"Coding, tool use, instruction following, planning\",\n  },\n  \"minimax:minimax-m2.1-lightning\": {\n    id: \"minimax:minimax-m2.1-lightning\",\n    provider: \"minimax\",\n    name: \"MiniMax M2.1 Lightning\",\n    description:\n      \"Faster M2.1 variant (~100 TPS). Same performance, higher throughput.\",\n    contextWindow: 205000,\n    pricing: { input: 0.3, output: 2.4, cached: 0.03 },\n    capabilities: [\"function-calling\"],\n    userFriendlyDescription:\n      \"Speed-optimized M2.1. Same smarts, nearly 2x faster output.\",\n    bestFor: \"Low-latency coding, real-time applications, fast responses\",\n  },\n\n  // Z.ai GLM Models (via Vercel AI Gateway)\n  \"zai:glm-4.6\": {\n    id: \"zai:glm-4.6\",\n    provider: \"zai\",\n    name: \"GLM 4.6\",\n    description:\n      \"Latest GLM. Enhanced coding, long-context, reasoning, and agentic applications.\",\n    contextWindow: 200000,\n    pricing: { input: 0.45, output: 1.8, cached: 0.11 },\n    capabilities: [\"function-calling\"],\n    hostOrder: [\"deepinfra\", \"fireworks\"],\n    userFriendlyDescription:\n      \"Versatile Chinese model. Strong at coding, reasoning, and agentic tasks with large context.\",\n    bestFor: \"Coding, agentic applications, long-context tasks\",\n  },\n  \"zai:glm-4.7\": {\n    id: \"zai:glm-4.7\",\n    provider: \"zai\",\n    name: \"GLM 4.7\",\n    description:\n      \"Latest flagship with stronger coding and multi-step reasoning.\",\n    contextWindow: 200000,\n    pricing: { input: 0.6, output: 2.2, cached: 0.11 },\n    capabilities: [\"function-calling\", \"thinking\"],\n    hostOrder: [\"deepinfra\", \"fireworks\"],\n    userFriendlyDescription:\n      \"Powerful coding model. Strong at agentic tasks and multi-step reasoning.\",\n    bestFor: \"Coding, agentic workflows, multi-step reasoning\",\n  },\n  \"zai:glm-4.6v-flash\": {\n    id: \"zai:glm-4.6v-flash\",\n    provider: \"zai\",\n    name: \"GLM 4.6V Flash\",\n    description:\n      \"Multimodal vision model. SOTA visual understanding. Low-latency.\",\n    contextWindow: 128000,\n    pricing: { input: 0, output: 0 },\n    capabilities: [\"vision\", \"function-calling\"],\n    userFriendlyDescription:\n      \"Fast vision model. Quick image understanding with low latency. Free preview.\",\n    bestFor: \"Visual understanding, fast multimodal, image analysis\",\n  },\n  \"zai:glm-4.5-air\": {\n    id: \"zai:glm-4.5-air\",\n    provider: \"zai\",\n    name: \"GLM 4.5 Air\",\n    description:\n      \"Lightweight MoE (106B total / 12B active). Agent-oriented foundation model.\",\n    contextWindow: 128000,\n    pricing: { input: 0.2, output: 1.1 },\n    capabilities: [\"function-calling\"],\n    userFriendlyDescription:\n      \"Lightweight agent. Compact model optimized for agentic workflows and tool use.\",\n    bestFor: \"Agentic tasks, cost-efficient, lightweight\",\n    isInternalOnly: true,\n  },\n\n  // DeepSeek Models\n  \"deepseek:deepseek-r1\": {\n    id: \"deepseek:deepseek-r1\",\n    provider: \"deepseek\",\n    name: \"DeepSeek R1\",\n    description: \"671B MoE reasoning model. Extended thinking.\",\n    contextWindow: 128000,\n    pricing: { input: 0.55, output: 2.19 },\n    capabilities: [\"thinking\", \"function-calling\"],\n    hostOrder: [\"cerebras\", \"groq\"],\n    reasoning: {\n      type: \"deepseek-tag-extraction\",\n      tagName: \"think\",\n      applyMiddleware: true,\n    },\n    knowledgeCutoff: \"November 2024\",\n    userFriendlyDescription:\n      \"Innovative reasoner. Massive model (671 billion parameters) with groundbreaking reasoning architecture.\",\n    bestFor:\n      \"Complex reasoning, innovative architecture, research applications\",\n  },\n  \"deepseek:deepseek-v3.2\": {\n    id: \"deepseek:deepseek-v3.2\",\n    provider: \"deepseek\",\n    name: \"DeepSeek V3.2\",\n    description:\n      \"Official successor to V3.2-Exp. Combined thinking + tool use.\",\n    contextWindow: 128000,\n    pricing: { input: 0.27, output: 1.1 },\n    capabilities: [\"thinking\", \"function-calling\"],\n    reasoning: {\n      type: \"deepseek-tag-extraction\",\n      tagName: \"think\",\n      applyMiddleware: true,\n    },\n    userFriendlyDescription:\n      \"Balanced thinker with tools. Combines reasoning capabilities with tool use at affordable pricing.\",\n    bestFor: \"Reasoning with tools, cost-effective thinking, general purpose\",\n  },\n  \"deepseek:deepseek-v3.2-thinking\": {\n    id: \"deepseek:deepseek-v3.2-thinking\",\n    provider: \"deepseek\",\n    name: \"DeepSeek V3.2 Thinking\",\n    description: \"Thinking mode of DeepSeek V3.2 for complex reasoning.\",\n    contextWindow: 128000,\n    pricing: { input: 0.27, output: 1.1 },\n    capabilities: [\"thinking\"],\n    reasoning: {\n      type: \"deepseek-tag-extraction\",\n      tagName: \"think\",\n      applyMiddleware: true,\n    },\n    userFriendlyDescription:\n      \"Pure reasoning mode. Focused on complex problem-solving without tool use distractions.\",\n    bestFor: \"Pure reasoning, complex analysis, thought-intensive tasks\",\n  },\n\n  // Free Models via OpenRouter\n  \"openrouter:deepseek-r1-0528\": {\n    id: \"openrouter:deepseek-r1-0528\",\n    provider: \"deepseek\",\n    name: \"DeepSeek R1 0528\",\n    description: \"671B MoE reasoning model via OpenRouter (May 2025 release).\",\n    contextWindow: 163840,\n    pricing: { input: 0, output: 0 },\n    capabilities: [\"thinking\"],\n    actualModelId: \"deepseek/deepseek-r1-0528:free\",\n    gateway: \"openrouter\",\n    reasoning: {\n      type: \"deepseek-tag-extraction\",\n      tagName: \"think\",\n      applyMiddleware: true,\n    },\n    knowledgeCutoff: \"May 2025\",\n    userFriendlyDescription:\n      \"Powerful reasoning at zero cost. 671B parameters with visible chain-of-thought.\",\n    bestFor: \"Complex reasoning, experimentation, cost-conscious users\",\n  },\n  \"openrouter:devstral-2512\": {\n    id: \"openrouter:devstral-2512\",\n    provider: \"mistral\",\n    name: \"Devstral 2512\",\n    description: \"123B agentic coding model by Mistral AI.\",\n    contextWindow: 262144,\n    pricing: { input: 0, output: 0 },\n    capabilities: [\"function-calling\"],\n    actualModelId: \"mistralai/devstral-2512:free\",\n    gateway: \"openrouter\",\n    userFriendlyDescription:\n      \"State-of-the-art agentic coding. Explores codebases and orchestrates multi-file changes.\",\n    bestFor: \"Code generation, agentic coding tasks, large codebases\",\n  },\n  \"openrouter:gpt-oss-120b\": {\n    id: \"openrouter:gpt-oss-120b\",\n    provider: \"openai\",\n    name: \"GPT-OSS 120B\",\n    description: \"117B MoE model with configurable reasoning.\",\n    contextWindow: 131072,\n    pricing: { input: 0, output: 0 },\n    capabilities: [\"thinking\", \"function-calling\"],\n    actualModelId: \"openai/gpt-oss-120b:free\",\n    gateway: \"openrouter\",\n    reasoning: {\n      type: \"openai-reasoning-effort\",\n      effortMapping: { low: \"low\", medium: \"medium\", high: \"high\" },\n      summaryLevel: \"detailed\",\n      useResponsesAPI: false,\n    },\n    userFriendlyDescription:\n      \"Large open-source model with reasoning. 117B params, 5.1B active per pass.\",\n    bestFor: \"Reasoning tasks, complex analysis, cost-conscious users\",\n  },\n  \"openrouter:gpt-oss-20b\": {\n    id: \"openrouter:gpt-oss-20b\",\n    provider: \"openai\",\n    name: \"GPT-OSS 20B\",\n    description: \"21B MoE model optimized for low-latency inference.\",\n    contextWindow: 131072,\n    pricing: { input: 0, output: 0 },\n    capabilities: [\"thinking\", \"function-calling\"],\n    actualModelId: \"openai/gpt-oss-20b:free\",\n    gateway: \"openrouter\",\n    reasoning: {\n      type: \"openai-reasoning-effort\",\n      effortMapping: { low: \"low\", medium: \"medium\", high: \"high\" },\n      summaryLevel: \"detailed\",\n      useResponsesAPI: false,\n    },\n    userFriendlyDescription:\n      \"Fast open-source reasoning model. 21B params, 3.6B active per pass.\",\n    bestFor: \"Quick reasoning, low-latency tasks, cost-conscious users\",\n  },\n  \"openrouter:glm-4.5-air\": {\n    id: \"openrouter:glm-4.5-air\",\n    provider: \"zai\",\n    name: \"GLM-4.5 Air\",\n    description: \"Lightweight MoE for agent-centric applications.\",\n    contextWindow: 131072,\n    pricing: { input: 0, output: 0 },\n    capabilities: [\"thinking\", \"function-calling\"],\n    actualModelId: \"z-ai/glm-4.5-air:free\",\n    gateway: \"openrouter\",\n    userFriendlyDescription:\n      \"Agent-focused model with optional reasoning mode. Lightweight and fast.\",\n    bestFor: \"Agentic tasks, tool use, real-time interaction\",\n  },\n  \"openrouter:qwen3-coder\": {\n    id: \"openrouter:qwen3-coder\",\n    provider: \"alibaba\",\n    name: \"Qwen3 Coder\",\n    description: \"480B coding specialist with 35B active params.\",\n    contextWindow: 262000,\n    pricing: { input: 0, output: 0 },\n    capabilities: [\"function-calling\"],\n    actualModelId: \"qwen/qwen3-coder:free\",\n    gateway: \"openrouter\",\n    userFriendlyDescription:\n      \"Massive coding model at zero cost. 480B total params, optimized for code tasks.\",\n    bestFor: \"Code generation, agentic coding, long-context reasoning\",\n  },\n  \"openrouter:kimi-k2\": {\n    id: \"openrouter:kimi-k2\",\n    provider: \"kimi\",\n    name: \"Kimi K2\",\n    description: \"1T param MoE with 32B active, strong coding/reasoning.\",\n    contextWindow: 32768,\n    pricing: { input: 0, output: 0 },\n    capabilities: [],\n    actualModelId: \"moonshotai/kimi-k2:free\",\n    gateway: \"openrouter\",\n    userFriendlyDescription:\n      \"Trillion-parameter model excelling at coding and reasoning benchmarks.\",\n    bestFor: \"Code synthesis, reasoning tasks\",\n  },\n  \"openrouter:llama-3.3-70b\": {\n    id: \"openrouter:llama-3.3-70b\",\n    provider: \"meta\",\n    name: \"Llama 3.3 70B\",\n    description: \"Meta's multilingual dialogue model.\",\n    contextWindow: 131072,\n    pricing: { input: 0, output: 0 },\n    capabilities: [\"function-calling\"],\n    actualModelId: \"meta-llama/llama-3.3-70b-instruct:free\",\n    gateway: \"openrouter\",\n    userFriendlyDescription:\n      \"Strong multilingual model supporting 8 languages including English, German, French.\",\n    bestFor: \"Multilingual dialogue, general purpose, instruction following\",\n  },\n  \"openrouter:gemini-2.0-flash-exp\": {\n    id: \"openrouter:gemini-2.0-flash-exp\",\n    provider: \"google\",\n    name: \"Gemini 2.0 Flash Exp\",\n    description: \"Experimental Gemini with 1M context and fast TTFT.\",\n    contextWindow: 1048576,\n    pricing: { input: 0, output: 0 },\n    capabilities: [\"vision\", \"function-calling\"],\n    actualModelId: \"google/gemini-2.0-flash-exp:free\",\n    gateway: \"openrouter\",\n    userFriendlyDescription:\n      \"Experimental Gemini with massive 1M context window and fast time-to-first-token.\",\n    bestFor: \"Long documents, multimodal tasks, fast responses\",\n  },\n};\n\n/**\n * Pre-computed metrics cache for performance\n * Avoids recomputing benchmarks/metrics on every render\n */\nconst MODEL_METRICS_CACHE = new Map<string, ComputedMetrics>();\n\n/**\n * Get computed metrics for a model (with caching)\n * Includes benchmark scores, speed tier, cost tier, percentiles\n *\n * @param modelId - Model ID (e.g., \"openai:gpt-5\")\n * @returns Computed metrics or undefined if model not found\n */\nexport function getModelMetrics(modelId: string): ComputedMetrics | undefined {\n  const model = MODEL_CONFIG[modelId];\n  if (!model) return undefined;\n\n  if (!MODEL_METRICS_CACHE.has(modelId)) {\n    // Compute all models for percentile calculations\n    const allModels = Object.values(MODEL_CONFIG);\n    MODEL_METRICS_CACHE.set(modelId, computeModelMetrics(model, allModels));\n  }\n\n  return MODEL_METRICS_CACHE.get(modelId)!;\n}\n","\"use client\";\n\nimport { api } from \"@blah-chat/backend/convex/_generated/api\";\nimport { useMutation } from \"convex/react\";\nimport { useEffect, useState } from \"react\";\nimport { useUserPreference } from \"./useUserPreference\";\n// import { toast } from \"sonner\"; // Optional notification on error\n\nexport function useRecentModels() {\n  const recentModels = useUserPreference(\"recentModels\");\n  // @ts-ignore - Type depth exceeded with complex Convex mutation (85+ modules)\n  const updatePrefs = useMutation(api.users.updatePreferences);\n\n  const [localRecents, setLocalRecents] = useState<string[]>([]);\n\n  // Sync from Convex on load\n  useEffect(() => {\n    setLocalRecents(recentModels);\n  }, [recentModels]);\n\n  const addRecent = async (modelId: string) => {\n    // If it's already the most recent, do nothing\n    if (localRecents[0] === modelId) return;\n\n    const current = localRecents;\n\n    // Remove if exists, prepend new, limit to 3\n    const filtered = current.filter((id) => id !== modelId);\n    const updated = [modelId, ...filtered].slice(0, 3);\n\n    // Optimistic update\n    setLocalRecents(updated);\n\n    // Persist\n    try {\n      await updatePrefs({ preferences: { recentModels: updated } });\n    } catch (err) {\n      setLocalRecents(current); // Rollback\n      console.error(\"Failed to update recent models\", err);\n    }\n  };\n\n  return { recents: localRecents, addRecent };\n}\n"],"names":[],"mappings":"+CAgBO,IAAM,EAAkD,CAE7D,eAAgB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EAC9D,oBAAqB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EACnE,oBAAqB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EAGnE,4BAA6B,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EAC3E,8BAA+B,CAC7B,aAAc,GACd,OAAQ,GACR,UAAW,EACb,EACA,6BAA8B,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EAG5E,wBAAyB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EACvE,0BAA2B,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EAGzE,aAAc,CAAE,aAAc,IAAK,OAAQ,GAAI,UAAW,EAAG,EAC7D,kBAAmB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EACjE,aAAc,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EAG5D,uBAAwB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EACtE,uBAAwB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EAGtE,qBAAsB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EACpE,sBAAuB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,EACrE,qBAAsB,CAAE,aAAc,GAAI,OAAQ,GAAI,UAAW,EAAG,CACtE,EAMM,EAAiE,CAErE,SAAU,CAAE,KAAM,aAAc,IAAK,IAAK,EAC1C,UAAW,CAAE,KAAM,aAAc,IAAK,GAAI,EAG1C,KAAM,CAAE,KAAM,OAAQ,IAAK,GAAI,EAG/B,mBAAoB,CAAE,KAAM,MAAO,EACnC,aAAc,CAAE,KAAM,MAAO,EAG7B,QAAS,CAAE,KAAM,MAAO,EACxB,kBAAmB,CAAE,KAAM,MAAO,EAClC,cAAe,CAAE,KAAM,MAAO,EAC9B,4BAA6B,CAAE,KAAM,QAAS,CAChD,EAKM,EAA4C,CAChD,OAAQ,GACR,UAAW,GACX,OAAQ,GACR,IAAK,GACL,SAAU,GACV,KAAM,GACN,QAAS,GACT,WAAY,GACZ,KAAM,GACN,SAAU,GACV,QAAS,GACT,QAAS,GACT,MAAO,GACP,KAAM,GACN,IAAK,EACP,EAKM,EAA2C,CAC/C,KAAM,GACN,KAAM,GACN,MAAO,IACP,MAAO,IACP,KAAM,EACN,IAAK,IACL,KAAM,KACN,MAAO,GACT,EAKO,SAAS,EAAmB,CAAkB,EAEnD,IAAM,EAAY,CAAc,CAAC,EAAM,EAAE,CAAC,CAC1C,GAAI,EACF,OAAO,EADM,AAMf,IAAM,EAAc,CAAiB,CAAC,AADrB,EAAM,QAAQ,CACgB,EAAI,GAG/C,EAAa,EACX,EAAY,EAAM,IAAI,CAAC,WAAW,GACxC,IAAK,GAAM,CAAC,EAAM,EAAK,GAAI,OAAO,OAAO,CAAC,GACxC,GAAI,EAAU,QAAQ,CAAC,CADoC,EAC7B,CAC5B,EAAa,EACb,KACF,CAGF,IAAI,EAAe,KAAK,KAAK,CAAC,EAAc,GACxC,EAAS,KAAK,KAAK,CAAC,EAAc,EAAa,IAC/C,EADqD,AACzC,KAAK,KAAK,CAAC,EAAc,EAAa,KAsBtD,IAvBiF,GAI7E,EAAM,YAAY,CAAC,QAAQ,CAAC,sBAAsB,CACpD,GAAa,GACb,GAAgB,IAEd,EAAM,YAAY,CAAC,QAAQ,CAAC,aAAa,CAC3C,GAAa,GACb,GAAgB,GAEd,EAAM,YAAY,CAAC,QAAQ,CAAC,WAAW,CAEzC,EAAe,KAAK,GAAG,CAAC,EAAc,GAAA,EAEpC,EAAM,OAAO,EAAE,CAEjB,EAAe,KAAK,GAAG,CAAC,EAAc,IACtC,EAAS,KAAK,GAAG,CAAC,EAAQ,KAIrB,CACL,aAAc,KAAK,GAAG,CAAC,EAAG,KAAK,GAAG,CAAC,IAAK,IACxC,OAAQ,KAAK,GAAG,CAAC,EAAG,KAAK,GAAG,CAAC,IAAK,IAClC,UAAW,KAAK,GAAG,CAAC,EAAG,KAAK,GAAG,CAAC,IAAK,GACvC,CACF,CA6DA,SAAS,EACP,CAAyB,CACzB,CAAmB,EAEnB,QAAc,IAAV,GAA4C,AAArB,GAAwB,GAAd,MAAM,CACzC,OAAO,AAGT,IAAM,EAAc,EAAU,MAAM,CAAC,AAAC,QAAY,IAAN,GAAmB,EAAI,GACnE,GAA2B,GAAG,CAA1B,EAAY,MAAM,CACpB,OAAO,AAGT,IAAM,EAAe,IAAI,EAAY,CAAC,IAAI,CAAC,CAAC,EAAG,IAAM,EAAI,GAEzD,OAAO,KAAK,KAAK,CADJ,AACM,EADO,MAAM,CAAC,AAAC,GAAM,EAAI,GAAO,MAAM,CAC/B,EAAa,MAAM,CAAI,IACnD,CAMO,SAAS,EACd,CAAkB,CAClB,CAAyB,EAGzB,IAUI,EACA,EACA,EAZE,EAAS,EAAmB,GAC5B,EAAsB,KAA6B,KAAf,CAAC,EAAM,EAAE,CAAC,CAG9C,CAAE,KAAM,CAAS,CAAE,IAAK,CAAQ,CAAE,CAvF1C,AAuF6C,SAvFpC,AAAa,CAAkB,EAEtC,IAAM,EAAgB,CAAW,CAAC,EAAM,QAAQ,CAAC,CACjD,GAAI,EACF,OAAO,EAIT,IALmB,AAKb,EAAY,EAAM,IAAI,CAAC,WAAW,GAClC,EAAU,EAAM,EAAE,CAAC,WAAW,GAEpC,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,OAAO,OAAO,CAAC,GACxC,GAAI,EAAU,KADwC,GAChC,CAAC,IAAQ,EAAQ,QAAQ,CAAC,GAC9C,GADoD,IAC7C,SAKX,AAAI,EAAM,YAAY,CAAC,QAAQ,CAAC,sBAAsB,AAGlD,EAAM,YAAY,CAAC,QAAQ,CAAC,aAAe,CAAC,EAAU,QAAQ,CAAC,SAF1D,CAAE,AAEkE,KAF5D,MAAO,GAKpB,EAAM,OAAO,CAIV,CAJY,AAIV,KAAM,QAAS,EAC1B,CAD6B,CA2D6B,GAGlD,CAAE,KAAM,CAAQ,CAAE,GA9DkB,KA8DT,CAAc,CAAE,CAAG,AAxDtD,SAAqB,AAAZ,CAA8B,EACrC,GAAI,EAAM,OAAO,CACf,CADiB,KACV,CAAE,KAAM,SAAU,QAAS,CAAE,EAGtC,IAAM,EAAU,CAAC,EAAM,OAAO,CAAC,KAAK,CAAG,EAAM,OAAO,CAAC,MAAA,AAAM,EAAI,SAE3D,AAAJ,EAAc,EACL,CADQ,AACN,KAAM,iBAAU,CAAQ,EAE/B,EAAU,GACL,CADS,AACP,KAAM,mBAAY,CAAQ,EAE9B,CAAE,KAAM,UAAW,SAAQ,CACpC,EA0CkE,GAOhE,GAAI,EAAW,CACb,IAAM,EAAkB,EAAU,GAAG,CACnC,AAAC,GAAM,EAAmB,GAAG,YAAY,EAErC,EAAY,EAAU,GAAG,CAAC,AAAC,GAAM,EAAmB,GAAG,MAAM,EAC7D,EAAe,EAAU,GAAG,CAAC,AAAC,GAAM,EAAmB,GAAG,SAAS,EAEzE,EAAyB,EACvB,EAAO,YAAY,CACnB,GAEF,EAAmB,EAAkB,EAAO,MAAM,CAAE,GACpD,EAAsB,EAAkB,EAAO,SAAS,CAAE,EAC5D,CAEA,MAAO,WACL,WACA,WACA,iBACA,yBACA,mBACA,EACA,0CACA,CACF,CACF,CAKO,SAAS,EAAoB,CAA8B,SAChE,KAAmB,IAAf,EACK,KADqB,SAG1B,GAAc,GAAW,CAAP,QAClB,GAAc,GAAW,CAAP,SAClB,GAAc,GAAW,CAAP,SAClB,GAAc,GAAW,CAAP,eACf,aACT,CAKO,SAAS,EAAa,CAAwB,EACnD,GAAM,WAAE,CAAS,UAAE,CAAQ,CAAE,CAAG,EAEhC,GAAI,EACF,MAAO,CAAA,CADK,CACF,EAAS,cAAc,GAAG,IAAI,CAAC,CAG3C,OAAQ,GACN,IAAK,aACH,MAAO,wBACT,KAAK,OACH,MAAO,iBACT,KAAK,SACH,MAAO,gBACT,KAAK,OACH,MAAO,wBACX,CACF,CAKO,SAAS,EAAY,CAAwB,EAClD,GAAM,UAAE,CAAQ,gBAAE,CAAc,CAAE,CAAG,EAErC,GAAuB,GAAG,CAAtB,EACF,MAAO,eAGT,IAAM,EAAY,CAAC,CAAC,EAAE,EAAe,OAAO,CAAC,GAAG,MAAM,CAAC,CAEvD,OAAQ,GACN,IAAK,SACH,MAAO,CAAA,EAAG,EAAU,kBAAkB,CAAC,AACzC,KAAK,WACH,MAAO,CAAA,EAAG,EAAU,gBAAgB,CAAC,AACvC,KAAK,UACH,MAAO,CAAA,EAAG,EAAU,qBAAqB,CAAC,AAC9C,CACF,2ICzRO,IAAM,EAA4C,CAIvD,eAAgB,CACd,GAAI,eACJ,SAAU,SACV,KAAM,QACN,YACE,qEACF,cAAe,IACf,QAAS,CAAE,MAAO,IAAK,OAAQ,GAAM,OAAQ,GAAK,EAClD,aAAc,CAAC,WAAY,SAAU,mBAAmB,CACxD,UAAW,CACT,KAAM,0BACN,cAAe,CAAE,IAAK,MAAO,OAAQ,SAAU,KAAM,MAAO,EAC5D,aAAc,WACd,iBAAiB,CACnB,EACA,gBAAiB,aACjB,wBACE,0GACF,QAAS,wDACX,EACA,oBAAqB,CACnB,GAAI,oBACJ,SAAU,SACV,KAAM,aACN,YAAa,uDACb,cAAe,IACf,QAAS,CAAE,MAAO,IAAM,OAAQ,GAAK,OAAQ,IAAM,EACnD,aAAc,CAAC,SAAU,mBAAmB,CAC5C,gBAAiB,aACjB,wBACE,iFACF,QAAS,+DACX,EACA,oBAAqB,CACnB,GAAI,oBACJ,SAAU,SACV,KAAM,aACN,YAAa,qDACb,cAAe,IACf,QAAS,CAAE,MAAO,IAAM,OAAQ,IAAM,OAAQ,IAAM,EACpD,aAAc,CAAC,mBAAmB,CAClC,gBAAiB,aACjB,wBACE,6FACF,QAAS,+CACX,EAGA,iBAAkB,CAChB,GAAI,iBACJ,SAAU,SACV,KAAM,UACN,YACE,iEACF,cAAe,MACf,QAAS,CAAE,MAAO,KAAM,OAAQ,GAAM,OAAQ,IAAM,EACpD,aAAc,CAAC,WAAY,SAAU,mBAAmB,CACxD,UAAW,CACT,KAAM,0BACN,cAAe,CAAE,IAAK,MAAO,OAAQ,SAAU,KAAM,MAAO,EAC5D,aAAc,WACd,iBAAiB,CACnB,EACA,gBAAiB,gBACjB,wBACE,oHACF,QAAS,uDACX,EACA,uBAAwB,CACtB,GAAI,uBACJ,SAAU,SACV,KAAM,gBACN,YAAa,6CACb,cAAe,MACf,QAAS,CAAE,MAAO,KAAM,OAAQ,GAAM,OAAQ,IAAM,EACpD,aAAc,CAAC,WAAY,mBAAmB,CAC9C,UAAW,CACT,KAAM,0BACN,cAAe,CAAE,IAAK,MAAO,OAAQ,SAAU,KAAM,MAAO,EAC5D,aAAc,WACd,iBAAiB,CACnB,EACA,gBAAiB,gBACjB,wBACE,wFACF,QAAS,2DACX,EACA,yBAA0B,CACxB,GAAI,yBACJ,SAAU,SACV,KAAM,kBACN,YACE,qEACF,cAAe,MACf,QAAS,CAAE,MAAO,IAAM,OAAQ,EAAK,OAAQ,IAAM,EACnD,aAAc,CAAC,SAAU,mBAAmB,CAC5C,gBAAiB,gBACjB,wBACE,uFACF,QAAS,kEACX,EAGA,iBAAkB,CAChB,GAAI,iBACJ,SAAU,SACV,KAAM,UACN,YACE,6FACF,cAAe,IACf,QAAS,CAAE,MAAO,KAAM,OAAQ,GAAM,OAAQ,GAAK,EACnD,aAAc,CAAC,WAAY,SAAU,mBAAmB,CACxD,UAAW,CACT,KAAM,0BACN,cAAe,CAAE,IAAK,MAAO,OAAQ,SAAU,KAAM,MAAO,EAC5D,aAAc,WACd,iBAAiB,CACnB,EACA,gBAAiB,aACjB,wBACE,uGACF,QAAS,kEACX,EACA,sBAAuB,CACrB,GAAI,sBACJ,SAAU,SACV,KAAM,eACN,YAAa,0DACb,cAAe,MACf,QAAS,CAAE,MAAO,KAAM,OAAQ,GAAM,OAAQ,GAAK,EACnD,aAAc,CAAC,SAAU,mBAAmB,CAC5C,gBAAiB,aACjB,wBACE,4FACF,QAAS,+DACX,EACA,qBAAsB,CACpB,GAAI,qBACJ,SAAU,SACV,KAAM,cACN,YACE,0EACF,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,EAAI,EACnC,aAAc,CAAC,mBAAoB,WAAW,CAC9C,UAAW,CAAC,WAAY,OAAO,CAC/B,wBACE,6EACF,QAAS,6DACT,gBAAgB,CAClB,EACA,sBAAuB,CACrB,GAAI,sBACJ,SAAU,SACV,KAAM,eACN,YACE,4EACF,cAAe,MACf,QAAS,CAAE,MAAO,IAAM,OAAQ,EAAI,EACpC,aAAc,CAAC,mBAAoB,WAAW,CAC9C,UAAW,CAAC,WAAY,OAAQ,YAAY,CAC5C,wBACE,2FACF,QAAS,0DACT,gBAAgB,CAClB,EAGA,4BAA6B,CAC3B,GAAI,4BACJ,SAAU,YACV,KAAM,kBACN,YAAa,wCACb,cAAe,IACf,QAAS,CAAE,MAAO,EAAK,OAAQ,GAAM,OAAQ,EAAI,EACjD,aAAc,CACZ,SACA,mBACA,WACA,oBACD,CACD,UAAW,CACT,KAAM,8BACN,cAAe,CAAE,IAAK,IAAM,OAAQ,KAAO,KAAM,GAAM,EACvD,WAAY,iCACd,EACA,gBAAiB,aACjB,wBACE,yGACF,QAAS,yDACX,EACA,8BAA+B,CAC7B,GAAI,8BACJ,SAAU,YACV,KAAM,oBACN,YAAa,iCACb,cAAe,IACf,QAAS,CAAE,MAAO,EAAK,OAAQ,GAAM,OAAQ,EAAI,EACjD,aAAc,CACZ,SACA,mBACA,WACA,oBACD,CACD,UAAW,CACT,KAAM,8BACN,cAAe,CAAE,IAAK,IAAM,OAAQ,KAAO,KAAM,GAAM,EACvD,WAAY,iCACd,EACA,gBAAiB,aACjB,wBACE,sGACF,QAAS,4CACX,EACA,6BAA8B,CAC5B,GAAI,6BACJ,SAAU,YACV,KAAM,mBACN,YAAa,0BACb,cAAe,IACf,QAAS,CAAE,MAAO,EAAK,OAAQ,EAAK,OAAQ,EAAI,EAChD,aAAc,CAAC,SAAU,mBAAmB,CAC5C,gBAAiB,aACjB,wBACE,sFACF,QACE,sEACJ,EAGA,0BAA2B,CACzB,GAAI,0BACJ,SAAU,SACV,KAAM,mBACN,YACE,gEACF,cAAe,QACf,QAAS,CACP,MAAO,IACP,OAAQ,GACR,OAAQ,KACR,UAAW,GACb,EACA,aAAc,CAAC,SAAU,mBAAoB,WAAW,CACxD,UAAW,CACT,KAAM,yBACN,cAAe,CACb,IAAK,KACL,OAAQ,MACR,KAAM,KACR,CACF,EACA,wBACE,6HACF,QACE,wEACF,gBAAiB,cACnB,EACA,wBAAyB,CACvB,GAAI,wBACJ,SAAU,SACV,KAAM,iBACN,YACE,iEACF,cAAe,QACf,QAAS,CACP,MAAO,KACP,OAAQ,EACR,OAAQ,GACV,EACA,aAAc,CAAC,SAAU,mBAAoB,WAAW,CACxD,UAAW,CACT,KAAM,yBACN,cAAe,CACb,IAAK,KACL,OAAQ,MACR,KAAM,KACR,CACF,EACA,gBAAiB,eACjB,wBACE,iHACF,QAAS,uDACX,EACA,wBAAyB,CACvB,GAAI,wBACJ,SAAU,SACV,KAAM,iBACN,YACE,6GACF,cAAe,IACf,QAAS,CACP,MAAO,GACP,OAAQ,EACR,OAAQ,IACV,EACA,aAAc,CAAC,SAAU,mBAAoB,WAAW,CACxD,UAAW,CACT,KAAM,yBACN,cAAe,CACb,IAAK,KACL,OAAQ,MACR,KAAM,KACR,CACF,EACA,gBAAiB,cACjB,wBACE,yHACF,QACE,yEACJ,EACA,0BAA2B,CACzB,GAAI,0BACJ,SAAU,SACV,KAAM,mBACN,YAAa,wDACb,cAAe,QACf,QAAS,CACP,MAAO,KACP,OAAQ,GACR,OAAQ,IACV,EACA,aAAc,CAAC,SAAU,mBAAmB,CAC5C,gBAAiB,cACjB,wBACE,0FACF,QAAS,gEACX,EACA,+BAAgC,CAC9B,GAAI,+BACJ,SAAU,SACV,KAAM,wBACN,YAAa,wDACb,cAAe,QACf,QAAS,CACP,MAAO,MACP,OAAQ,IACR,OAAQ,KACV,EACA,aAAc,CAAC,SAAU,mBAAmB,CAC5C,gBAAiB,cACjB,wBACE,gFACF,QAAS,iEACX,EACA,8BAA+B,CAC7B,GAAI,8BACJ,KAAM,yBACN,SAAU,SACV,cAAe,QACf,QAAS,CACP,MAAO,EACP,OAAQ,EAEV,EACA,aAAc,CAAC,mBAAoB,WAAW,CAC9C,YACE,yEACF,gBAAgB,EAChB,UAAW,CACT,KAAM,wBACN,aAAc,CACZ,IAAK,MACL,OAAQ,SACR,KAAM,MACR,EACA,iBAAiB,CACnB,EACA,gBAAiB,cACjB,wBACE,gGACF,QAAS,2DACX,EAEA,oCAAqC,CACnC,GAAI,oCACJ,KAAM,uCACN,SAAU,SACV,cAAe,MACf,QAAS,CACP,MAAO,EACP,OAAQ,EACV,EACA,aAAc,CAAC,mBAAoB,SAAU,WAAW,CACxD,YACE,4GACF,gBAAgB,EAChB,UAAW,CACT,KAAM,wBACN,aAAc,CACZ,IAAK,MACL,OAAQ,SACR,KAAM,MACR,EACA,iBAAiB,CACnB,EACA,gBAAiB,cACjB,wBACE,qGACF,QAAS,yDACX,EAEA,gCAAiC,CAC/B,GAAI,gCACJ,SAAU,SACV,KAAM,yBACN,YAAa,wDACb,cAAe,MACf,QAAS,CACP,MAAO,GACP,OAAQ,GACV,EACA,aAAc,CAAC,mBAAoB,SAAS,CAC5C,gBAAgB,EAChB,gBAAiB,cACjB,wBACE,2GACF,QAAS,6CACX,EAGA,kBAAmB,CACjB,GAAI,kBACJ,SAAU,MACV,KAAM,cACN,YAAa,wCACb,cAAe,MACf,QAAS,CAAE,MAAO,EAAK,OAAQ,CAAI,EACnC,aAAc,CAAC,mBAAmB,CAClC,cAAe,4BACf,gBAAiB,YACjB,wBACE,wFACF,QAAS,wDACX,EAEA,oBAAqB,CACnB,GAAI,oBACJ,SAAU,MACV,KAAM,gBACN,YAAa,kDACb,cAAe,IACf,QAAS,CAAE,MAAO,EAAK,OAAQ,CAAI,EACnC,aAAc,CAAC,mBAAmB,CAClC,cAAe,8BACf,gBAAiB,YACjB,wBACE,6GACF,QAAS,iDACX,EACA,8BAA+B,CAC7B,GAAI,8BACJ,SAAU,MACV,KAAM,4BACN,YAAa,iDACb,cAAe,IACf,QAAS,CAAE,MAAO,EAAK,OAAQ,CAAI,EACnC,aAAc,CAAC,WAAY,mBAAmB,CAC9C,cAAe,0BACf,gBAAiB,YACjB,wBACE,uGACF,QACE,yEACJ,EACA,uBAAwB,CACtB,GAAI,uBACJ,SAAU,MACV,KAAM,iBACN,YAAa,8BACb,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,CAAI,EACnC,aAAc,CAAC,WAAW,CAC1B,gBAAiB,YACjB,wBACE,qGACF,QAAS,+CACX,EAGA,iCAAkC,CAChC,GAAI,iCACJ,SAAU,aACV,KAAM,sBACN,YAAa,yCACb,cAAe,MACf,QAAS,CAAE,MAAO,EAAK,OAAQ,CAAI,EACnC,aAAc,CAAC,WAAW,CAC1B,gBAAiB,mBACjB,wBACE,kIACF,QACE,2EACJ,EACA,uBAAwB,CACtB,GAAI,uBACJ,SAAU,aACV,KAAM,YACN,YAAa,iCACb,cAAe,IACf,QAAS,CAAE,MAAO,EAAK,OAAQ,EAAK,EACpC,aAAc,EAAE,CAChB,gBAAiB,mBACjB,wBACE,oGACF,QAAS,qDACX,EAEA,6BAA8B,CAC5B,GAAI,6BACJ,SAAU,aACV,KAAM,kBACN,YAAa,2BACb,cAAe,MACf,QAAS,CAAE,MAAO,EAAK,OAAQ,CAAI,EACnC,aAAc,CAAC,WAAW,CAC1B,gBAAiB,mBACjB,wBACE,+FACF,QAAS,4DACX,EACA,mBAAoB,CAClB,GAAI,mBACJ,SAAU,aACV,KAAM,QACN,YAAa,2BACb,cAAe,MACf,QAAS,CAAE,MAAO,EAAK,OAAQ,CAAI,EACnC,aAAc,EAAE,CAChB,gBAAiB,mBACjB,wBACE,qFACF,QAAS,wDACX,EAEA,qBAAsB,CACpB,GAAI,qBACJ,SAAU,OACV,KAAM,gBACN,YAAa,4DACb,cAAe,MACf,QAAS,CAAE,MAAO,IAAM,OAAQ,GAAK,EACrC,aAAc,CAAC,mBAAmB,CAClC,UAAW,CAAC,WAAY,OAAO,CAC/B,wBACE,sGACF,QAAS,4DACT,gBAAgB,CAClB,EACA,wBAAyB,CACvB,GAAI,wBACJ,SAAU,OACV,KAAM,uBACN,YACE,8EACF,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,EAAI,EACnC,aAAc,CAAC,SAAU,mBAAmB,CAC5C,UAAW,CAAC,WAAY,OAAO,CAC/B,wBACE,sFACF,QAAS,gDACX,EACA,qBAAsB,CACpB,GAAI,qBACJ,SAAU,OACV,KAAM,oBACN,YAAa,6DACb,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,EAAI,EACnC,aAAc,CAAC,mBAAmB,CAClC,UAAW,CAAC,WAAY,OAAO,CAC/B,wBACE,kFACF,QAAS,mDACX,EAGA,0BAA2B,CACzB,GAAI,0BACJ,SAAU,UACV,KAAM,kBACN,YACE,8EACF,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,GAAI,EACnC,aAAc,CAAC,mBAAoB,SAAS,CAC5C,wBACE,+FACF,QAAS,0DACX,EACA,yBAA0B,CACxB,GAAI,yBACJ,SAAU,UACV,KAAM,yBACN,YAAa,wDACb,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,EAAI,EACnC,aAAc,CAAC,mBAAmB,CAClC,wBACE,mFACF,QAAS,4DACX,EAGA,oBAAqB,CACnB,GAAI,oBACJ,SAAU,UACV,KAAM,aACN,YACE,6EACF,cAAe,MACf,QAAS,CAAE,MAAO,IAAK,OAAQ,EAAK,OAAQ,GAAK,EACjD,aAAc,CAAC,mBAAoB,WAAW,CAC9C,wBACE,iFACF,QAAS,mDACX,EACA,2BAA4B,CAC1B,GAAI,2BACJ,SAAU,UACV,KAAM,oBACN,YAAa,0DACb,cAAe,OACf,QAAS,CAAE,MAAO,IAAM,OAAQ,GAAI,EACpC,aAAc,CAAC,mBAAmB,CAClC,wBACE,8FACF,QAAS,6DACT,gBAAgB,CAClB,EAGA,qBAAsB,CACpB,GAAI,qBACJ,SAAU,OACV,KAAM,UACN,YACE,sFACF,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,GAAI,EACnC,aAAc,CAAC,mBAAmB,CAClC,UAAW,CAAC,YAAa,YAAY,CACrC,wBACE,8FACF,QAAS,8CACT,gBAAgB,CAClB,EACA,8BAA+B,CAC7B,GAAI,8BACJ,SAAU,OACV,KAAM,mBACN,YACE,mFACF,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,IAAK,OAAQ,GAAK,EACjD,aAAc,CAAC,mBAAoB,WAAW,CAC9C,UAAW,CAAC,YAAa,YAAY,CACrC,wBACE,qGACF,QAAS,kEACT,gBAAgB,CAClB,EAGA,qBAAsB,CACpB,GAAI,qBACJ,SAAU,UACV,KAAM,aACN,YACE,+EACF,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,IAAK,OAAQ,GAAK,EACjD,aAAc,CAAC,mBAAmB,CAClC,UAAW,CAAC,YAAY,CACxB,wBACE,iFACF,QAAS,8CACX,EACA,uBAAwB,CACtB,GAAI,uBACJ,SAAU,UACV,KAAM,eACN,YACE,oFACF,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,IAAK,OAAQ,GAAK,EACjD,aAAc,CAAC,mBAAmB,CAClC,wBACE,qEACF,QAAS,mDACX,EACA,iCAAkC,CAChC,GAAI,iCACJ,SAAU,UACV,KAAM,yBACN,YACE,uEACF,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,IAAK,OAAQ,GAAK,EACjD,aAAc,CAAC,mBAAmB,CAClC,wBACE,8DACF,QAAS,4DACX,EAGA,cAAe,CACb,GAAI,cACJ,SAAU,MACV,KAAM,UACN,YACE,kFACF,cAAe,IACf,QAAS,CAAE,MAAO,IAAM,OAAQ,IAAK,OAAQ,GAAK,EAClD,aAAc,CAAC,mBAAmB,CAClC,UAAW,CAAC,YAAa,YAAY,CACrC,wBACE,8FACF,QAAS,kDACX,EACA,cAAe,CACb,GAAI,cACJ,SAAU,MACV,KAAM,UACN,YACE,iEACF,cAAe,IACf,QAAS,CAAE,MAAO,GAAK,OAAQ,IAAK,OAAQ,GAAK,EACjD,aAAc,CAAC,mBAAoB,WAAW,CAC9C,UAAW,CAAC,YAAa,YAAY,CACrC,wBACE,2EACF,QAAS,iDACX,EACA,qBAAsB,CACpB,GAAI,qBACJ,SAAU,MACV,KAAM,iBACN,YACE,mEACF,cAAe,MACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,CAAC,SAAU,mBAAmB,CAC5C,wBACE,+EACF,QAAS,uDACX,EACA,kBAAmB,CACjB,GAAI,kBACJ,SAAU,MACV,KAAM,cACN,YACE,8EACF,cAAe,MACf,QAAS,CAAE,MAAO,GAAK,OAAQ,GAAI,EACnC,aAAc,CAAC,mBAAmB,CAClC,wBACE,iFACF,QAAS,6CACT,gBAAgB,CAClB,EAGA,uBAAwB,CACtB,GAAI,uBACJ,SAAU,WACV,KAAM,cACN,YAAa,+CACb,cAAe,MACf,QAAS,CAAE,MAAO,IAAM,OAAQ,IAAK,EACrC,aAAc,CAAC,WAAY,mBAAmB,CAC9C,UAAW,CAAC,WAAY,OAAO,CAC/B,UAAW,CACT,KAAM,0BACN,QAAS,QACT,iBAAiB,CACnB,EACA,gBAAiB,gBACjB,wBACE,0GACF,QACE,mEACJ,EACA,yBAA0B,CACxB,GAAI,yBACJ,SAAU,WACV,KAAM,gBACN,YACE,gEACF,cAAe,MACf,QAAS,CAAE,MAAO,IAAM,OAAQ,GAAI,EACpC,aAAc,CAAC,WAAY,mBAAmB,CAC9C,UAAW,CACT,KAAM,0BACN,QAAS,QACT,iBAAiB,CACnB,EACA,wBACE,oGACF,QAAS,gEACX,EACA,kCAAmC,CACjC,GAAI,kCACJ,SAAU,WACV,KAAM,yBACN,YAAa,wDACb,cAAe,MACf,QAAS,CAAE,MAAO,IAAM,OAAQ,GAAI,EACpC,aAAc,CAAC,WAAW,CAC1B,UAAW,CACT,KAAM,0BACN,QAAS,QACT,iBAAiB,CACnB,EACA,wBACE,yFACF,QAAS,2DACX,EAGA,8BAA+B,CAC7B,GAAI,8BACJ,SAAU,WACV,KAAM,mBACN,YAAa,8DACb,cAAe,OACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,CAAC,WAAW,CAC1B,cAAe,iCACf,QAAS,aACT,UAAW,CACT,KAAM,0BACN,QAAS,QACT,iBAAiB,CACnB,EACA,gBAAiB,WACjB,wBACE,kFACF,QAAS,0DACX,EACA,2BAA4B,CAC1B,GAAI,2BACJ,SAAU,UACV,KAAM,gBACN,YAAa,2CACb,cAAe,OACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,CAAC,mBAAmB,CAClC,cAAe,+BACf,QAAS,aACT,wBACE,2FACF,QAAS,wDACX,EACA,0BAA2B,CACzB,GAAI,0BACJ,SAAU,SACV,KAAM,eACN,YAAa,8CACb,cAAe,OACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,CAAC,WAAY,mBAAmB,CAC9C,cAAe,2BACf,QAAS,aACT,UAAW,CACT,KAAM,0BACN,cAAe,CAAE,IAAK,MAAO,OAAQ,SAAU,KAAM,MAAO,EAC5D,aAAc,WACd,iBAAiB,CACnB,EACA,wBACE,6EACF,QAAS,yDACX,EACA,yBAA0B,CACxB,GAAI,yBACJ,SAAU,SACV,KAAM,cACN,YAAa,qDACb,cAAe,OACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,CAAC,WAAY,mBAAmB,CAC9C,cAAe,0BACf,QAAS,aACT,UAAW,CACT,KAAM,0BACN,cAAe,CAAE,IAAK,MAAO,OAAQ,SAAU,KAAM,MAAO,EAC5D,aAAc,WACd,iBAAiB,CACnB,EACA,wBACE,sEACF,QAAS,0DACX,EACA,yBAA0B,CACxB,GAAI,yBACJ,SAAU,MACV,KAAM,cACN,YAAa,kDACb,cAAe,OACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,CAAC,WAAY,mBAAmB,CAC9C,cAAe,wBACf,QAAS,aACT,wBACE,0EACF,QAAS,gDACX,EACA,yBAA0B,CACxB,GAAI,yBACJ,SAAU,UACV,KAAM,cACN,YAAa,iDACb,cAAe,MACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,CAAC,mBAAmB,CAClC,cAAe,wBACf,QAAS,aACT,wBACE,kFACF,QAAS,yDACX,EACA,qBAAsB,CACpB,GAAI,qBACJ,SAAU,OACV,KAAM,UACN,YAAa,yDACb,cAAe,MACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,EAAE,CAChB,cAAe,0BACf,QAAS,aACT,wBACE,yEACF,QAAS,iCACX,EACA,2BAA4B,CAC1B,GAAI,2BACJ,SAAU,OACV,KAAM,gBACN,YAAa,sCACb,cAAe,OACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,CAAC,mBAAmB,CAClC,cAAe,yCACf,QAAS,aACT,wBACE,sFACF,QAAS,+DACX,EACA,kCAAmC,CACjC,GAAI,kCACJ,SAAU,SACV,KAAM,uBACN,YAAa,qDACb,cAAe,QACf,QAAS,CAAE,MAAO,EAAG,OAAQ,CAAE,EAC/B,aAAc,CAAC,SAAU,mBAAmB,CAC5C,cAAe,mCACf,QAAS,aACT,wBACE,mFACF,QAAS,kDACX,CACF,EAMM,EAAsB,IAAI,IASzB,SAAS,EAAgB,CAAe,EAC7C,IAAM,EAAQ,CAAY,CAAC,EAAQ,CACnC,GAAK,CAAD,EAEJ,GAAI,CAFQ,AAEP,EAAoB,GAAG,CAAC,CAFV,EAEoB,CAErC,IAAM,EAAY,OAAO,MAAM,CAAC,GAChC,EAAoB,GAAG,CAAC,EAAS,EAAoB,EAAO,GAC9D,CAEA,OAAO,EAAoB,GAAG,CAAC,GACjC,mFCliCA,IAAA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,CAAA,CAAA,OAAA,IAAA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QAGO,SAAS,IACd,IAAM,EAAe,CAAA,EAAA,EAAA,iBAAA,AAAiB,EAAC,gBAEjC,EAAc,CAAA,EAAA,EAAA,WAAA,AAAW,EAAC,EAAA,GAAG,CAAC,KAAK,CAAC,iBAAiB,EAErD,CAAC,EAAc,EAAgB,CAAG,CAAA,EAAA,EAAA,QAAA,AAAQ,EAAW,EAAE,EAG7D,CAAA,EAAA,EAAA,SAAA,AAAS,EAAC,KACR,EAAgB,EAClB,EAAG,CAAC,EAAa,EAEjB,IAAM,EAAY,MAAO,IAEvB,GAAI,CAAY,CAAC,EAAE,GAAK,EAAS,OAKjC,IAAM,EAAW,EAAQ,MAAM,CAAC,AAAC,GAAO,IAAO,GACzC,EAAU,CAAC,KAAY,EAAS,CAAC,KAAK,CAAC,EAAG,GAGhD,EAAgB,GAGhB,GAAI,CACF,MAAM,EAAY,CAAE,YAAa,CAAE,aAAc,CAAQ,CAAE,EAC7D,CAAE,MAAO,EAAK,CACZ,EAbc,GAcd,QAAQ,GADQ,EACH,CAAC,OADY,WAAW,eACW,EAClD,CACF,EAEA,MAAO,CAAE,QAAS,YAAc,CAAU,CAC5C"}