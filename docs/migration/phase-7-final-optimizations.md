# Phase 7: Final Optimizations & N+1 Fixes

**Timeline**: Week 8-10 (8-10 days)
**Impact**: Eliminate N+1 queries, optimize indexes, normalize memory metadata
**Risk Level**: Low - Performance optimizations, no breaking schema changes

---

## Why This Phase?

After Phases 1-6, major normalization complete. Phase 7 addresses:
1. **N+1 queries** (bookmarks, snippets)
2. **Missing indexes** for common queries
3. **Memory metadata** normalization (optional cleanup)
4. **Manual vector scoring** inefficiency

---

## Optimization 1: Fix Bookmarks N+1 Query

### Current Problem

**File**: `convex/bookmarks.ts:86-98`

```typescript
// âš ï¸ N+1 pattern: For each bookmark, fetch message + conversation
const bookmarksWithData = await Promise.all(
  bookmarks.map(async (bookmark) => {
    const message = await ctx.db.get(bookmark.messageId);  // N queries
    const conversation = message
      ? await ctx.db.get(message.conversationId)  // N more queries
      : null;
    return { ...bookmark, message, conversation };
  }),
);
```

**Performance**: 10 bookmarks = 20 DB queries

### Solution: Batch Fetch

```typescript
// âœ… Batch fetch pattern
export const getUserBookmarks = query({
  args: { limit: v.optional(v.number()) },
  handler: async (ctx, { limit = 50 }) => {
    const userId = await getCurrentUserId(ctx);

    // Get bookmarks
    const bookmarks = await ctx.db
      .query("bookmarks")
      .withIndex("by_user", q => q.eq("userId", userId))
      .order("desc")
      .take(limit);

    // Batch fetch messages by ID
    const messageIds = bookmarks.map(b => b.messageId);
    const messages = await Promise.all(
      messageIds.map(id => ctx.db.get(id))
    );

    // Batch fetch conversations by ID (deduplicated)
    const conversationIds = [
      ...new Set(
        messages.filter(Boolean).map(m => m!.conversationId)
      ),
    ];
    const conversations = await Promise.all(
      conversationIds.map(id => ctx.db.get(id))
    );
    const conversationMap = new Map(
      conversations.filter(Boolean).map(c => [c!._id, c!])
    );

    // Join in memory
    return bookmarks.map((bookmark, i) => ({
      ...bookmark,
      message: messages[i],
      conversation: messages[i]
        ? conversationMap.get(messages[i]!.conversationId)
        : null,
    }));
  },
});
```

**Performance**: 10 bookmarks = 3 queries (1 bookmarks + 1 messages batch + 1 conversations batch)

**Impact**: 7x faster for typical usage

---

## Optimization 2: Add Missing Indexes

### Index Audit

Current schema missing optimal indexes for common queries:

```typescript
// convex/schema.ts - Add these indexes

bookmarks: defineTable({
  // ... existing fields ...
})
  .index("by_user", ["userId"])
  .index("by_message", ["messageId"])
  .index("by_conversation", ["conversationId"])
  .index("by_user_created", ["userId", "createdAt"]),  // âœ… ADD: For sorted recent bookmarks

messages: defineTable({
  // ... existing fields ...
})
  .index("by_conversation", ["conversationId"])
  .index("by_user", ["userId"])
  .index("by_status", ["status"])
  .index("by_parent", ["parentMessageId"])
  .index("by_comparison_group", ["comparisonGroupId"])
  .index("by_consolidated_message", ["consolidatedMessageId"])
  .index("by_conversation_created", ["conversationId", "createdAt"]),  // âœ… ADD: For ordered messages
  .index("by_conversation_role", ["conversationId", "role"]),  // âœ… ADD: For filtering user/assistant

memories: defineTable({
  // ... existing fields ...
})
  .index("by_user", ["userId"])
  .index("by_importance", ["userId", "metadata.importance"])
  .index("by_conversation", ["conversationId"]),  // âœ… ADD: Missing!
  .index("by_user_category", ["userId", "metadata.category"]),  // âœ… ADD: For filtered searches

feedback: defineTable({
  // ... existing fields ...
})
  .index("by_user", ["userId"])
  .index("by_status", ["status"])
  .index("by_type", ["feedbackType"])
  .index("by_created", ["createdAt"])
  .index("by_priority", ["priority"])
  .index("by_assigned", ["assignedTo"])
  .index("by_status_priority", ["status", "priority"]),  // âœ… ADD: For filtered views
```

### Migration

```typescript
// convex/migrations/007_add_missing_indexes.ts
"use node";

// No code migration needed - indexes are schema-only
// Deploy schema, Convex builds indexes automatically

export const addMissingIndexes = internalAction({
  handler: async (ctx) => {
    console.log("âœ… Indexes added via schema deployment");
    console.log("   Convex will build indexes in background");
    console.log("   Monitor progress in dashboard under 'Indexes'");
  },
});
```

---

## Optimization 3: Normalize Memory Metadata (Optional)

### Current Problem

Memory metadata stored as nested object (convex/schema.ts:303-330):

```typescript
metadata: v.object({
  category: v.string(),
  importance: v.optional(v.number()),
  reasoning: v.optional(v.string()),
  extractedAt: v.optional(v.number()),
  sourceConversationId: v.optional(v.id("conversations")),
  confidence: v.optional(v.number()),
  // ... 10+ more fields
})
```

**Issues**:
- Can't query "memories extracted from conversation X" without full table scan
- Can't filter by `extractedAt` range efficiently
- `sourceConversationId` duplicates `conversationId` field

### Solution: Extract Metadata Table

```typescript
// convex/schema.ts - Add after memories table

memoryMetadata: defineTable({
  memoryId: v.id("memories"),
  conversationId: v.id("conversations"),
  messageId: v.optional(v.id("messages")),
  category: v.string(),
  importance: v.optional(v.number()),
  confidence: v.optional(v.number()),
  reasoning: v.optional(v.string()),
  extractedAt: v.number(),
  createdAt: v.number(),
})
  .index("by_memory", ["memoryId"])
  .index("by_conversation", ["conversationId"])
  .index("by_message", ["messageId"])
  .index("by_extracted_at", ["extractedAt"]),  // For time-based queries
```

**Migration**: Similar pattern to previous phases (backfill, dual-write, cleanup)

**Decision**: This is **optional** - only if you need to query memory extraction history. Otherwise, current nested metadata works fine.

---

## Optimization 4: Hybrid Search Performance

### Current Problem

**File**: `convex/search/hybrid.ts:141-181`

```typescript
// âš ï¸ Manual vector scoring - collects ALL messages
const results = await ctx.db
  .query("messages")
  .withIndex("by_user", q => q.eq("userId", args.userId))
  .filter(q => q.neq(q.field("embedding"), undefined))
  .collect();  // Fetches every message

const withScores = results.map((msg) => {
  const score = msg.embedding
    ? cosineSimilarity(args.embedding, msg.embedding)
    : 0;
  return { ...msg, score };
});
```

**Problem**: For user with 1000 messages, computes 1000 cosine similarities client-side.

### Solution: Use Convex Vector Index

Convex now supports native vector search (already in schema!):

```typescript
// convex/schema.ts:286-290 - Already exists!
.vectorIndex("by_embedding", {
  vectorField: "embedding",
  dimensions: 1536,
  filterFields: ["conversationId", "userId"],
})
```

**Update hybrid search**:

```typescript
// convex/search/hybrid.ts - Refactor vectorSearch function

async function vectorSearch(
  ctx: QueryCtx,
  embedding: number[],
  userId: Id<"users">,
  limit: number
) {
  // Use native vector index instead of manual scoring
  const results = await ctx.db
    .query("messages")
    .withIndex("by_embedding", q =>
      q.similar("embedding", embedding, limit * 2)  // Get more for filtering
        .eq("userId", userId)
    )
    .collect();

  return results.slice(0, limit);
}
```

**Performance**: 1000 messages manual scoring (500ms) â†’ native vector search (<50ms)

**Impact**: 10x faster semantic search

---

## Optimization 5: Conversation Message Count Caching

### Current Problem

**File**: `convex/schema.ts:124`

```typescript
messageCount: v.optional(v.number()),
```

Field exists but not always updated.

### Solution: Maintain Count on Insert/Delete

```typescript
// In createMessage mutation:
await ctx.db.patch(conversationId, {
  messageCount: (conversation.messageCount || 0) + 1,
  lastMessageAt: Date.now(),
});

// In deleteMessage mutation:
await ctx.db.patch(conversationId, {
  messageCount: Math.max((conversation.messageCount || 1) - 1, 0),
});
```

**Benefit**: Fast conversation list with message counts (no need to count messages per conversation)

---

## Migration Checklist

### Day 1-2: Indexes
- [ ] Add missing indexes to schema
- [ ] Deploy schema
- [ ] Monitor index build progress in dashboard
- [ ] Verify query performance improvements

### Day 3-5: N+1 Fixes
- [ ] Refactor bookmarks query (batch fetch)
- [ ] Refactor snippets query (same pattern)
- [ ] Test with 50+ bookmarks (measure query time)
- [ ] Deploy and verify

### Day 6-8: Vector Search
- [ ] Update hybrid search to use native vector index
- [ ] Test semantic search performance
- [ ] Compare before/after query times
- [ ] Deploy and verify

### Day 9-10: Optional Cleanup
- [ ] Decide on memory metadata normalization (optional)
- [ ] Update messageCount maintenance (if not already done)
- [ ] Final testing of all optimizations
- [ ] Performance audit

---

## Critical Gotchas

### 1. Index Build Time

**Gotcha**: Large tables take time to index. Convex builds indexes in background, but queries may be slow until complete.

**Check progress**: Convex dashboard â†’ Indexes tab â†’ "Building" status

**Workaround**: Deploy indexes during low-traffic period.

### 2. Vector Index Filter Fields

**Current** (schema.ts:288):
```typescript
filterFields: ["conversationId", "userId"],
```

**Gotcha**: Can only filter by these fields in vector search. If you need to filter by `role` (user vs assistant), must filter after query.

**Solution**: Either add `role` to filterFields or filter results in memory.

### 3. Batch Fetch Order Preservation

**Gotcha**: `Promise.all()` preserves order, but `ctx.db.get()` for deleted entities returns `null`.

**Pattern**:
```typescript
const messages = await Promise.all(ids.map(id => ctx.db.get(id)));
// messages[i] may be null if deleted
```

**Solution**: Filter out nulls or handle gracefully.

### 4. Message Count Drift

**Scenario**: Message count gets out of sync if:
- Message inserted but count increment fails
- Message deleted but count decrement fails

**Solution**: Add rebuild function (run monthly or on-demand):

```typescript
export const rebuildMessageCounts = internalMutation({
  handler: async (ctx) => {
    const conversations = await ctx.db.query("conversations").collect();

    for (const conv of conversations) {
      const messages = await ctx.db
        .query("messages")
        .withIndex("by_conversation", q => q.eq("conversationId", conv._id))
        .collect();

      await ctx.db.patch(conv._id, {
        messageCount: messages.length,
      });
    }
  },
});
```

---

## Testing Checklist

- [ ] **Bookmarks query**: 50 bookmarks load in <200ms (vs 1s+ before)
- [ ] **Hybrid search**: 1000 messages searched in <100ms
- [ ] **New indexes**: Queries use correct indexes (check Convex dashboard)
- [ ] **Message count**: Accurate after insert/delete
- [ ] **Memory metadata**: (If migrated) Queries work correctly

---

## Success Metrics

- **N+1 elimination**: Bookmarks query 5-10x faster
- **Vector search**: 10x faster semantic search
- **Index coverage**: 100% of common queries use indexes
- **Data accuracy**: Message counts match reality

---

## Final Validation

After Phase 7, run comprehensive audit:

### Performance Metrics
```typescript
// Measure these query times:
- getUserBookmarks (50 items): <200ms
- hybridSearch (1000 messages): <100ms
- getConversationMessages (100 msgs): <100ms
- getUserPreferences (all prefs): <50ms
- getProjectConversations (50 convs): <150ms
```

### Data Integrity Checks
```typescript
// Run these validation queries:
1. All tags are normalized (no case variants)
2. All project links have matching conversation.projectId
3. All attachment links have valid storageId
4. All message counts match actual message queries
5. All token usage totals match sum of messages
```

### Schema Cleanup
```typescript
// Final checklist:
- [ ] All DEPRECATED fields removed from schema
- [ ] All dual-write logic removed from mutations
- [ ] All old monthly rebuild crons deleted
- [ ] All fallback queries removed (no more old array reads)
```

---

## ðŸŽ‰ Migration Complete!

After Phase 7:
- **40% message size reduction** (Phases 1-2)
- **10x faster cascade deletes** (Phase 3)
- **Atomic preference updates** (Phase 4)
- **Centralized tag management** (Phase 5)
- **Per-model usage tracking** (Phase 6)
- **N+1 queries eliminated** (Phase 7)

**Total impact**: SQL-ready, normalized, performant schema with zero downtime.

---

## Rollback Strategy (Emergency)

If critical issues found post-migration:

### 1. Identify Affected Phase
Check which phase introduced the issue (schema changes, queries, mutations).

### 2. Revert Schema (Last Resort)
```typescript
// Re-add deprecated fields as optional
// Restore dual-write logic
// Restore fallback queries
```

### 3. Data Integrity Check
```typescript
// Run validation scripts
// Check for data loss
// Verify counts match
```

### 4. Gradual Rollback
- Don't delete new tables immediately (keep for 30 days)
- Restore old query logic
- Monitor for 1 week before considering deletion

---

## Post-Migration Monitoring

**Week 1**: Daily checks
- Query performance dashboard
- Error logs (any new exceptions?)
- User feedback (any issues reported?)

**Week 2-4**: Weekly checks
- Data drift monitoring
- Storage savings verification
- Performance regression checks

**Month 2+**: Monthly audits
- Schema health check
- Index usage statistics
- Query optimization opportunities
